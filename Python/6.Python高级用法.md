## metaclass

> 定义：很多书都会翻译成 **元类**，仅从字面理解， meta 的确是元，本源，翻译没毛病。但理解时，应该把元理解为描述数据的超越数据
>
> 作用：有了 metaclass，就可以对子类进行操作，就像装饰器那样可以动态定制和修改被装饰的类，metaclass 可以动态的定制或修改继承它的子类。
>
> 注意：**元类、装饰器、类装饰器都可以归为元编程。**

要理解 metaclass 的底层原理，你需要深入理解 Python 类型模型。下面，将分三点来说明。

### 第一，所有的 Python 的用户定义类，都是 type 这个类的实例。

~~~ python
"""
参数详解：
params1: str 类名（任意字符串）
params2：tuple 当前创建的类需要继承的类
params3: dict 当前创建的类的成员(值、方法)
"""
# 使用type创建类，类是type类的实例 ==> 所以实例化new_class时在type的视觉实际上是将new_class当作可调用对象来调用，进而触发了type类的__call__方法
new_class = type("NewBase", (base_class,), {})

# 总结
"""
一句话总结：类是type类的实例
当在定义 class new_class(metaclass=MyMeta)时，会依次调用MyMeta的__new__ 和 __init__方法构建new_class类，
调用new_class的实例时，才会调用Mymeta的__call__方法
"""
# 举例
age = 18
print(age.__class__)  # <class 'int'>
print(age.__class__.__class__)  # <class 'type'>
~~~

### 第二，用户自定义类，只不过是 type 类的 `__call__` 运算符重载

当我们定义一个类的语句结束时，真正发生的情况，是 Python 调用 type 的 `__call__` 运算符。简单来说，当你定义一个类时，写成下面这样时：

~~~ python
class MyClass:
    data = 1

# Python 真正执行的是下面这段代码：
class = type(classname, superclasses, attributedict)
这里等号右边的 type(classname, superclasses, attributedict)，就是 type 的 __call__ 运算符重载，它会进一步调用

type.__new__(typeclass, classname, superclasses, attributedict)
type.__init__(class, classname, superclasses, attributedict)
~~~

### 第三，metaclass 是 type 的子类，通过替换 type 的 `__call__` 运算符重载机制，“超越变形”正常的类

```python
# 一旦你把一个类型 MyClass 的 metaclass 设置成 MyMeta，MyClass 就不再由原生的 type 创建，而是会调用 MyMeta 的 `__call__` 运算符重载。
class = type(classname, superclasses, attributedict) # 变为了class = MyMeta(classname, superclasses, attributedict)
```

### 使用元类实现创建类对象单例例子

~~~ python
class Singleton1(type):
    __instance = {}
    def __call__(cls, *args, **kwargs):
        if cls not in cls.__instance:
            cls.__instance[cls] = super(Singleton, cls).__call__(*args, **kwargs)
        return cls.__instance[cls]
    
class Singleton2(type):
    def __call__(cls, *args, **kwargs):
        if hasattr(cls, __instance):
            # cls.__instance[cls] = super(Singleton, cls).__call__(*args, **kwargs)
            cls.__instance= type.__call__(*args, **kwargs)
        return cls.__instance
~~~

# 元类编程

> 类是元类的示例，所以当类()当作函数调用时，则会调用元类的`__call__`方法

## 1.类是如何产生的

类是如何产生？这个问题也许你会觉得很傻。

实则不然，很多初学者只知道使用继承的表面形式来创建一个类，却不知道其内部真正的创建是由 `type` 来创建的。

type？这不是判断对象类型的函数吗？

是的，type通常用法就是用来判断对象的类型。但除此之外，他最大的用途是用来动态创建类。当Python**扫描到class**的语法的时候，就会调用type函数进行类的创建。

## 2.如何使用type创建类

首先，`type()` 需要接收三个参数

1. 类的名称，若不指定，也要传入空字符串：`""`
2. 父类，注意以tuple的形式传入，若没有父类也要传入空tuple：`()`，默认继承object
3. 绑定的方法或属性，注意以dict的形式传入

示例：

~~~ python
# 准备一个基类（父类）
class BaseClass:
    def talk(self):
        print("i am people")

# 准备一个方法
def say(self):
    print("hello")

# 使用type来创建User类
User = type("User", (BaseClass, ), {"name":"user", "say":say})
~~~



# 魔术方法

## 描述符

> 同时实现以下三个魔术方法的类称为描述符类，实现其中任一一个魔术方法的类称为非数据描述符类
>
> 数据描述器与非数据描述器的区别在于：它们相对于实例的字典的优先级不同(访问)
>
> 注意：描述符类只能管理类成员，不能管理实例成员，但所有的实例共享共享描述符

* `__set__(被管理的实例, 值)`
* `__get__(被管理的类, 被管理的实例)`
* `__delete__(被管理的实例)`

示例：

~~~ python
class Descriptor:
    def __init__(self):
        self.tmp = None  # 需要创建一个临时变量来替代对被管理类的属性

    def __set__(self, instance, value):
        self.tmp = value

    def __get__(self, instance, owner):
        print(instance)
        print(owner)
        return self.tmp

    def __delete__(self, instance):
        print(instance)
        del self.tmp


class MyClass:
    name = Descriptor()  # 将类成员交付给描述符类管理
    def __init__(self, name):
        self.name = name  # 所有的实例共享描述符


my_obj = MyClass()

my_obj.name = 123
print(my_obj.name)
del my_obj.name
# print(my_obj.name)
~~~

模仿实现property装饰器：

~~~ python
"""
使用描述符协议模仿实现property,与types中的DynamicClassAttribute类类似
注意：使用TestProperty装饰后，math不再是一个函数，而是一个实例
程序一运行就优先加载装饰器
"""
class TestProperty(object):
    def __init__(self, fget=None, fset=None, fdel=None, doc=None):
        self.fget = fget  # 1. --> def math(self):
        self.fset = fset  # 4. --> def math(self, value):
        self.fdel = fdel
        self.__doc__ = doc

    def __get__(self, obj, objtype=None):
        print("in __get__", type(self))
        if obj is None:
            return self
        if self.fget is None:
            raise AttributeError
        return self.fget(obj)

    def __set__(self, obj, value):
        print("in __set__", type(self))
        if self.fset is None:
            raise AttributeError
        self.fset(obj, value)

    def __delete__(self, obj):
        print("in __delete__", type(self))

        if self.fdel is None:
            raise AttributeError
        self.fdel(obj)

    def getter(self, fget):
        print("in getter")
        return type(self)(fget, self.fset, self.fdel, self.__doc__)

    def setter(self, fset):
        print("in setter")
        return type(self)(self.fget, fset, self.fdel, self.__doc__)  # 3.创建一个新的实例

    def deleter(self, fdel):
        print("in deleter")
        return type(self)(self.fget, self.fset, fdel, self.__doc__)


class Student:
    def __init__(self, name):
        self.name = name
        self._math = 0

    @TestProperty  # 1.产生一个新的实例赋值给math
    def math(self):  # 使用TestProperty装饰后，math不再是一个函数，而是一个实例
        return self._math

    @math.setter  # 2.math作为参数传递给TestProperty中的setter
    def math(self, value):
        if 0 <= value <= 100:
            self._math = value
        else:
            raise ValueError("Valid value must be in [0, 100]")
std = Student('xm')
~~~





## 获取成员

### `__getitem__`

> 只适用于所有的`[]`运算符；

### `__getattr__`

> 用于获取类属性，适用于对象`.`运算符，优先级在`__getattribute__`之后，只有找不到对象属性时，才会调用此方法

### `__getattribute__`

> 用于获取类属性，适用于对象`.`运算符，优先级比`__getattr__`高，无论调用对象的什么属性，包括不存在的属性，都会首先调用此方法

## 设置成员

### `__setitem__`

> 设置对象成员
>
> 触发条件：将对象当作字典索引值时，例如：obj["name"]

### `__setattr__`

> 设置对象成员
>
> 触发条件：对象`.`属性 = xxx时触发

## 删除成员

### `__delitem__`

> 删除数据结构对象成员
>
> 触发条件：当使用`del obj[索引]`显示调用时删除某个成员时

### `__delattr__`

> 删除对象属性
>
> 触发条件：当使用`del obj.xxx` 显示调用删除某个属性时

### `__del__`

> 内存回收
>
> 触发条件：当程序停止时主动触发



## 属性访问顺序

1. 调用`__getattribute__`
2. 调用数据描述符
3. 调用当前对象的所属成员
4. 调用类的所属成员
5. 调用非数据描述符
6. 调用父类的所属成员
7. 调用`__getattr__`

注意：以上步骤是调用某个成员的访问顺序及优先级。一旦前面的能获取成员，就不会向后查找

### `__contains__`









列表推导式   --> [语法]

生成器(一种迭代器)表达式 --> (语法)，如果生成器表达式是一个函数调用过程中的唯一参数，那么不需要额外再用括号把它围 起来。例如：

~~~ python
tuple(ord(symbol) for symbol in symbols)
~~~



## operator模块

> from operator import mul 

* itemgetter

  ~~~ python
  """
  itemgetter 和 attrgetter 其实会自行构建函数。
  itemgetter 的常见用途：根据元组的某个字段给元组列表排序。
  如果把多个参数传给 itemgetter，它构建的函数会返回提取的值构成的元组：
  """
  # 示例1
  from operator import itemgetter
  
  tup = [("北京", 1), ("上海", 3), ("贵州", 2)]
  tup.sort(key=itemgetter(1))  # 从而避免编写平凡的lambda匿名函数
  ~~~

  

* attrgetter

  ~~~ python
  """
  attrgetter 与 itemgetter 作用类似，它创建的函数根据名称提取对象的属性。如果把
  多个属性名传给 attrgetter，它也会返回提取的值构成的元组。
  """
  
  from collections import namedtuple
  from operator import attrgetter
  
  metro_data = [
      ('Tokyo', 'JP', 36.933, (35.689722, 139.691667)),
      ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)),
      ('Mexico City', 'MX', 20.142, (19.433333, -99.133333)),
      ('New York-Newark', 'US', 20.104, (40.808611, -74.020386)),
      ('Sao Paulo', 'BR', 19.649, (-23.547778, -46.635833)),
  ]
  LatLong = namedtuple('LatLong', 'lat long')
  Metropolis = namedtuple('Metropolis', 'name cc pop coord')
  metro_areas = [Metropolis(name, cc, pop, LatLong(lat, long))
                 for name, cc, pop, (lat, long) in metro_data]
  
  name_lat = attrgetter('name', 'coord.lat')
  
  for city in sorted(metro_areas, key=attrgetter('coord.lat')):
      print(name_lat(city))
  
  ~~~

* methodcaller

  ~~~ python
  """
  它的作用与 attrgetter和 itemgetter 类似，它会自行创建函数。methodcaller 创建的函数会在对象上调用参数指定的方法
  """
  
  from operator import methodcaller
  
  s = 'The time has come'  # 对象
  upcase = methodcaller('upper')
  upcase(S)
  
  # methodcaller 还可以冻结某些参数
  hiphenate = methodcaller('replace', ' ', '-')
  hiphenate(s) 
  
  ~~~

## functools模块

* partial

  ~~~ python
  """
  partial 这个高阶函数用于部分应用一个函数
  部分应用是指，基于一个函数创建一个新的可调用对象，把原函数的某些参数固定。
  使用这个函数可以把接受一个或多个参数的函数改编成需要回调的 API，这样参数更少。
  partial 对象提供了访问原函数和固定参数的属性。
  """
  
  # 示例1
  from operator import mul
  from functools import partial
  triple = partial(mul, 3)
  triple(7)  # 21
  list(map(triple, range(1, 10)))  # [3, 6, 9, 12, 15, 18, 21, 24, 27]
  
  # 示例2
  使用 partial 构建一个便利的 Unicode 规范化函数
  import unicodedata, functools
  nfc = functools.partial(unicodedata.normalize, 'NFC')
  s1 = 'café'
  s2 = 'cafe\u0301'
  >>> s1, s2
  ('café', 'café')
  >>> s1 == s2
  False
  >>> nfc(s1) == nfc(s2)
  True
  
  # 访问原函数和固定参数的属性。
  picture.args
  picture.keywords 
  
  ~~~

  

## 使用一等函数实现设计模式

> 符合模式并不表示做得对。——Ralph Johnson
>
> 总结：当具体策略示例没有状态(示例属性)，可以把具体策略换成简单的函数，效率更高，还能去掉抽象类

~~~ python
from abc import ABC, abstractmethod
from collections import namedtuple

Customer = namedtuple('Customer', 'name fidelity')


class LineItem:
    def __init__(self, product, quantity, price):
        self.product = product
        self.quantity = quantity
        self.price = price

    def total(self):
        return self.price * self.quantity


class Order:  # 上下文
    def __init__(self, customer, cart, promotion=None):
        self.customer = customer
        self.cart = list(cart)
        self.promotion = promotion

    def total(self):
        if not hasattr(self, '__total'):
            self.__total = sum(item.total() for item in self.cart)
        return self.__total

    def due(self):
        if self.promotion is None:
            discount = 0
        else:
            discount = self.promotion.discount(self)
        return self.total() - discount

    def __repr__(self):
        fmt = '<Order total: {:.2f} due: {:.2f}>'
        return fmt.format(self.total(), self.due())


class Promotion(ABC):  # 策略：抽象基类
    @abstractmethod
    def discount(self, order):
        """返回折扣金额（正值）"""


class FidelityPromo(Promotion):  # 第一个具体策略
    """为积分为1000或以上的顾客提供5%折扣"""
    def discount(self, order):
        return order.total() * .05 if order.customer.fidelity >= 1000 else 0


class BulkItemPromo(Promotion):  # 第二个具体策略
    """单个商品为20个或以上时提供10%折扣"""

    def discount(self, order):
        discount = 0
        for item in order.cart:
            if item.quantity >= 20:
                discount += item.total() * .1
        return discount


class LargeOrderPromo(Promotion):  # 第三个具体策略
    """订单中的不同商品达到10个或以上时提供7%折扣"""

    def discount(self, order):
        distinct_items = {item.product for item in order.cart}
        if len(distinct_items) >= 10:
            return order.total() * .07
        return 0


joe = Customer('John Doe', 0)
ann = Customer('Ann Smith', 1100)

cart = [LineItem('banana', 4, .5),
        LineItem('apple', 10, 1.5),
        LineItem('watermellon', 5, 5.0)]

order = Order(ann, cart, FidelityPromo())
print(order)
~~~

## 函数装饰器何闭包

> 函数装饰器用于在源码中“标记”函数，以某种方式增强函数的行为。

装饰器是可调用的对象，其参数是另一个函数（被装饰的函数）。2 装饰器可能会处理被装 饰的函数，然后把它返回，或者将其替换成另一个函数或可调用对象。

装饰器的一大特性是，能把被装饰的函数替换成其他函数。第二个特性是，装饰器 在**加载模块**时立即执行。



## `__init__.py`文件的作用

~~~ python
__init__.py 文件的作用是将文件夹变为一个Python模块,Python 中的每个模块的包中，都有__init__.py 文件。
通常__init__.py 文件为空，但是我们还可以为它增加其他的功能。我们在导入一个包时，实际上是导入了它的__init__.py文件。
这样我们可以在__init__.py文件中批量导入我们所需要的模块，而不再需要一个一个的导入。
~~~







# 深入理解python特性(书籍)

## 1.1上下文管理器

类实现

总的来说，如果想将一个对象作为 上下文管理器，需要做的就是向其中添加__enter__和__exit__方 法。Python将在资源管理周期的适当时间调用这两种方法。

~~~ python
"""
当执行流程进入with语句上下文时，Python会调用__enter__获取资
源；离开with上下文时，Python会调用__exit__释放资源。

"""
class ManagedFile:
    def __init__(self, name):
        self.name = name

    def __enter__(self):
        self.file = open(self.name, 'w')
        return self.file

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.file:
            self.file.close()
~~~

在Python中，除了编写**基于类**的上下文管理器来支持with语句以外，标 准库中的contextlib 模块在上下文管理器基本协议的基础上提供了更 多抽象。如果你遇到的情形正好能用到contextlib提供的功能，那么 可以节省很多精力。

例如，使用contextlib.contextmanager装饰器能够为资源定义一个 基于**生成器**的工厂**函数**，该函数将自动支持with语句。下面的示例用 这种技术重写了之前的ManagedFile上下文管理器：

基于函数

~~~ python
from contextlib import contextmanager

@contextmanager
def managed_file(name):
    try:
        f = open(name, 'w')
        yield f
    finally:
        f.close()
~~~

这个managed_file()是生成器，开始先获取资源，之后暂停执行并产 生资源以供调用者使用。当调用者离开with上下文时，生成器继续执 行剩余的清理步骤，并将资源释放回系统。 基于类的实现和基于生成器的实现基本上是等价的，选择哪一种取决于 你的编码偏好。

## 1.2下划线、双下划线及其他

### 前置单下划线：_var

Python社区约定好单下划线表达的是某种意思，其 本身并不会影响程序的行为。 它通常对Python解释器没有特殊含义，前置下划线的意思是提示其他程序员，以单下划线开头的变量或方法只 在内部使用。PEP 8中定义了这个约定（PEP 8是最常用的Python代码风 格指南 ）

Python中的前置单下划线只是一个公认的约定，至少在涉及变 量名和方法名时是这样的。但是前置下划线会影响从模块中导入名称的 方式。

与 通配符导入不同，常规导入不受前置单下划线命名约定的影响

### 后置单下划线：var_

有时，某个变量最合适的名称已被Python语言中的关键字占用。因此， 诸如class或def的名称不能用作Python中的变量名。在这种情况下， 可以追加一个下划线来绕过命名冲突

总之，用一个后置单下划线来避免与Python关键字的命名冲突是一个约 定。PEP 8定义并解释了这个约定。

### 前置双下划线：__var

> 在Python社区中通常称双下划线为dunder。因为Python代码中经常出现 双下划线，所以为了简化发音，Python高手通常会将“双下划 线”（double underscore）简称为dunder 。 后续内容中会将dunder翻译成“双下划线方法”。——译者注 例如，`__baz`在英文中读作dunderbaz。与之类似，`__init__`读作 dunderinit，虽然按道理说应该是dunderinitdunder。 

双下划线前缀会让Python解释器重写属性名称，以避免子类中的命名冲突。

这也称为名称改写（name mangling），即解释器会更改变量的名称， 以便在稍后扩展这个类时避免命名冲突。

~~~ python
class Test:
    def __init__(self):
        self.foo = 11
        self._bar = 23
        self.__baz = 42

t = Test()
print(dir(t))  
# ['_Test__baz', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_bar', 'foo']

# 当有子类继承Test类时，子类属性中仍然存在_Test__baz
~~~

名称改写也适用于方法名，会影响在类环境中所有以双下划线 （dunder）开头的名称

下面这个名称改写的示例可能会令人惊讶：

~~~ python
_MangledGlobal__mangled = 23
class MangledGlobal:
    def test(self):
        return __mangled
print(MangledGlobal().test())  # 23
~~~

这个例子先声明`_MangledGlobal__mangled`为全局变量，然后在名 为MangledGlobal的类环境中访问变量。由于名称改写，类中的 test()方法仅用__mangled就能引用`_MangledGlobal__mangled`全局 变量。

`__mangled`以双下划线开头，因此Python解释器自动将名称扩展 为_MangledGlobal__mangled。这表明名称改写不专门与类属性绑 定，而是能够应用于**类环境**中**所有以双下划线开头**的名称。

### 前后双下划线：`__var__`

这也许有点令人惊讶——如果名字前后都使用双下划线，则不会发生名 称改写。前后由双下划线包围的变量不受Python解释器的影响：

~~~ python
class PrefixPostfixTest:
    def __init__(self):
        self.__bam__ = 42
print(PrefixPostfixTest().__bam__)  # 42
~~~

然而，同时具有前后双下划线的名称在Python中有特殊用途。像 __init__这样的对象构造函数，用来让对象可调用的__call__函数， 都遵循这条规则。 这些双下划线方法通常被称为魔法方法,但Python社区中的许多人（包 括我自己）不喜欢这个词。因为这个词像是暗示人们要退避三舍，但实 际上完全不必如此。双下划线方法是Python的核心功能，应根据需要使 用，其中并没有什么神奇或晦涩的内容。

但就命名约定而言，最好避免在自己的程序中使用以双下划线开头和结 尾的名称，以避免与Python语言的未来变更发生冲突。

### 单下划线：_

按照约定，单下划线有时用作名称，来表示变量是临时的或无关紧要 的。

应用领域：1.循环中并不需要访问运行的索引，2.解包表达式中还可使用单下划线表示一个“不关心”的变量来忽略特定 的值

同样，这个含义只是一个约定，不会触发Python解析器中的任何 特殊行为。单下划线只是一个**有效的变量名**，偶尔用于该目的。

除了用作临时变量之外，_在大多数Python REPL( 交互式解释器)中是一个特殊变量，表 示由解释器计算的上一个表达式的结果。

如果正在实时构建对象，有单下划线的话不用事先指定名称就能与之交 互：

~~~ python
list()
_.append(1)
_.append(2)
_.append(3)
print(_)  # [1,2,3]
~~~



## 1.3字符串格式化

### 第一种方法：“旧式”字符串格式化

字符串占位符：%s

16进制占位符：x%

如果将别名传递给%操作符，还可以在格式字符串中按名称替换变量：

~~~ python
'Hey %(name)s, there is a 0x%(errno)x error!' % {"name": name, "errno": errno } 
~~~

### 第二种方法：“新式”字符串格式化

> python3开始，后来移植到python2.7

### 第三种方法：字符串字面值插值（Python 3.6+）

Python 3.6增加了另一种格式化字符串的方法，称为格式化字符串字面 值（formatted string literal）。采用这种方法，可以在字符串常量内使用 嵌入的Python表达式：

~~~ python
f'Hello, {name}!'
f'Five plus ten is {a + b} and not {2 * (a + b)}.'  # 内联算术运算
~~~

字符串字面值也支持str.format()方法所使用的字符串格式化语法， 因此可以用相同的方式解决前两节中遇到的格式化问题：

~~~ python
f"Hey {name}, there's a {errno:#x} error!"
~~~

### 第四种方法：模板字符串

示例：

~~~ python
from string import Template

name = "alex"
t = Template('Hey, $name!')
print(t.substitute(name=name))
~~~

从上面可以看到，这里需要从Python的内置字符串模块中导 入Template类。模板字符串不是核心语言功能，而是由标准库中的模 块提供。 另一个区别是模板字符串不能使用格式说明符。因此，为了让之前的报 错字符串示例正常工作，需要手动将int错误码转换为一个十六进制字 符串：

~~~ python
from string import Template

name = "alex"
errno = 123
templ_string = 'Hey $name, there is a $error error!'
print(Template(templ_string).substitute(name=name, error=hex(errno)))
~~~

结果不错，但是你可能想知道什么时候应该在Python程序中使用模板字 符串。在我看来，最佳使用场景是用来处理程序用户生成的格式字符 串。因为模板字符串较为简单，所以是更安全的选择。 其他字符串格式化技术所用的语法更复杂，因而可能会给程序带来安全 漏洞。例如，格式字符串可以访问程序中的任意变量。 这意味着，如果恶意用户可以提供格式字符串，那么就可能泄露密钥和 其他敏感信息！下面用一个示例来简单演示一下这种攻击方式：

~~~ python
SECRET = 'this-is-a-secret'

class Error:
    def __init__(self):
        pass

err = Error()
user_input = '{error.__init__.__globals__[SECRET]}'
~~~

注意看，假想的攻击者访问格式字符串中的__globals__字典，从中提 取了秘密的字符串。吓人吧？用模板字符串就能避免这种攻击。因此， 如果处理从用户输入生成的格式字符串，用模板字符串更加安全。

~~~ python
>>> user_input = '${error.__init__.__globals__[SECRET]}'
>>> Template(user_input).substitute(error=err)
ValueError:
"Invalid placeholder in string: line 1, col 1"
~~~

达恩的Python字符串格式化**经验法则**： 

如果格式字符串是用户提供的，使用模板字符串来避免安全问题。 如果不是，再考虑Python版本：Python 3.6+使用字符串字面值插 值，老版本则使用“新式”字符串格式化。

## 2.1 函数是Python的头等对象

函数是Python的头等对象。可以把函数分配给变量、存储在数据结构 中、作为参数传递给其他函数，甚至作为其他函数的返回值。

Python程序中的所有数据都是由对象或对象之间的关系来表示的。 字 符串、列表和模块等都是对象。Python中的函数也不例外，同样是对 象。

函数对象及其名称是相互独立的实体，下面来验证一下。先删除该函数 的原始名称（yell），由于另一个名称（bark）仍然指向底层函数， 因此仍然可以通过bark调用该函数：

~~~ python
def yell():
    print("hello")
bark = yell()
del yell
bark()  # hello
~~~

顺便说一句，Python在创建函数时为每个函数附加一个用于调试的字符 串标识符。使用`__name__`属性可以访问这个内部标识符

~~~ python
bark.__name__  # yell
~~~

虽然函数的`__name__`仍然是yell，但已经无法用这个名称在代码中访 问函数对象。名称标识符仅仅用来辅助调试，指向函数的变量和函数本 身实际上是彼此独立的。

### 2.11 函数可存储在数据结构中

由于函数是头等对象，因此可以像其他对象一样存储在数据结构中。例如，可以将函数添加到列表中：

~~~ python
funcs = [bark, str.lower, str.capitalize]
~~~

### 2.12 函数可传递给其他函数

能接受其他函数作为参数的函数被称为高阶函数。高阶函数是函数式编 程风格中必不可少的一部分。

Python中具有代表性的高阶函数是内置的map函数。map接受一个函数对 象和一个可迭代对象，然后在可迭代对象中的每个元素上调用该函数来 生成结果。

### 2.13 函数可以嵌套

~~~ python
def outer():
    def inner():
        print("我是内部函数")
    return inner
~~~

### 2.14 函数可捕捉局部状态

前面介绍了函数可以包含内部函数，甚至可以从父函数返回（默认情况 下看不见的）内部函数。内部函数不仅可以从父函数返回，还可以捕获并携带父函数的某些状 态。这是什么意思呢？

~~~ python
def get_speak_func(text, volume):
    def whisper():
        return text.lower() + '...'
    def yell():
        return text.upper() + '!'
    if volume > 0.5:
        return yell
    else:
        return whisper
get_speak_func('Hello, World', 0.7)()  # 'HELLO, WORLD!'
~~~

拥有这种行为的函数被称为词法闭包（lexical closure），简称闭包。闭 包在程序流不在闭包范围内的情况下，也能记住**封闭作用域**（enclosing scope）中的值。

实际上，这意味着函数不仅可以返回行为，还可以预先配置这些行 为。用另一个例子来演示一下：

~~~ python
def make_adder(n):
    def add(x):
        return x + n
    return add
plus_3 = make_adder(3)
plus_s(5)  # 8
~~~

在这个例子中，make_adder作为**工厂函数**来创建和配置各种adder函数。注意，这些adder函数仍然可以访问make_adder函数中位于封闭作 用域中的参数n。

### 2.15 对象也可作为函数使用

虽然Python中的所有函数都是对象，但反之不成立。有些对象不是函 数，但依然可以调用，因此在许多情况下可以将其当作函数来对待。 如果一个对象是可调用的，意味着可以使用圆括号函数调用语法，甚至 可以传入调用参数。这些都由__call__双下划线方法完成。下面这个 类能够定义可调用对象：

~~~ python
class Adder:
    def __init__(self):
        self.n = n
    def __call__(self):
        return self.n + x
plus_3 = Adder(3)
plus(4)  # 7
~~~

在幕后，像函数那样“调用”一个对象实例实际上是在尝试执行该对象的 __call__方法。 当然，并不是所有的对象都可以调用，因此Python内置了callable函 数，用于检查一个对象是否可以调用。

## 2.2 lambda是单表达式函数

> 不必与名称绑定(匿名)

~~~ python
(lambda x, y: x + y)(5, 3)
~~~

从概念上讲，lambda表达式lambda x，y：x + y与用def声明函数相 同，但从语法上来说表达式位于lambda内部。两者的关键区别在于， lambda不必先将函数对象与名称绑定，只需在lambda中创建一个想要执 行的表达式，然后像普通函数那样立即调用进行计算。

lambda和普通函数定义之间还有另一个语法差异。lambda函数只能含有 一个表达式，这意味着lambda函数不能使用语句或注解（annotation）， 甚至不能使用返回语句。 那么应该如何从lambda返回值呢？执行lambda函数时会计算其中的表达 式，然后自动返回表达式的结果，所以其中总是有一个隐式的返回表达 式。因此有些人把lambda称为单表达式函数。

lambda还有一个有趣之处：与普通的嵌套函数一样，lambda也可以像词 法闭包那样工作。 词法闭包是什么？这只是对某种函数的一个奇特称呼，该函数能记住来 自某个封闭词法作用域的值，即使程序流已经不在作用域中也不例外。 下面用一个（相当学术的）例子来演示这个思想：

~~~ python
def make_adder(n):
    return lambda x: x + n


plus_3 = make_adder(3)
plus_5 = make_adder(5)

print(plus_3(4))  # 7
print(plus_5(4))  # 9
~~~

### 2.21不应过度使用lambda

将lambda和map()或filter()结合起来构建复杂的表达式也很难让人理 解，此时用列表解析式或生成器表达式通常会清晰不少：

~~~ python
# 有害：
>>> list(filter(lambda x: x % 2 == 0, range(16)))
[0, 2, 4, 6, 8, 10, 12, 14]
# 清晰：
>>> [x for x in range(16) if x % 2 == 0]
[0, 2, 4, 6, 8, 10, 12, 14]	
~~~

如果你发现自己在用lambda表达式做非常复杂的事，那么可以考虑定义 一个有恰当名称的独立函数。 从长远来看，少敲一些代码并不重要，同事（以及未来的自己）并不喜 欢花哨的炫耀，而是喜欢清晰可读的代码。

## 2.3 装饰器的力量

Python的装饰器可以用来临时扩展和修改可调用对象（函数、方法和 类）的行为，同时又不会永久修改可调用对象本身。 装饰器的一大用途是将通用的功能应用到现有的类或函数的行为上，这些功能包括：

* 日志（logging） 
* 访问控制和授权
* 衡量函数，如执行时间
* 限制请求速率（rate-limiting ）
* 缓存，等等

###   2.31 Python装饰器基础

那么装饰器到底是什么？装饰器是用来“装饰”或“包装”另一个函数的， 在被包装函数运行之前和之后执行一些代码。 装饰器可以用来定义可重用的代码块，改变或扩展其他函数的行为，而 无须永久性地修改包装函数本身。函数的行为只有在装饰后才会改变。 那么简单装饰器的实现会是什么样子的呢？用基本术语来说，装饰器是 可调用的，将可调用对象作为输入并返回另一个可调用对象。 下面这个函数就具有这种特性，因此可以认为它是最简单的装饰器：

~~~ python
def null_decorator(func):
	return func

def greet():
	return 'Hello!'
greet = null_decorator(greet)
greet()
~~~

注意，使用@语法会在定义时就立即修饰该函数。这样，若想访问未装 饰的原函数则需要折腾一番。因此如果想保留调用未装饰函数的能力， 那么还是要手动装饰需要处理的函数。

### 2.3.2 装饰器可以修改行为

在熟悉装饰器语法之后，下面来编写一个有实际作用的装饰器来修改被 装饰函数的行为。 这个装饰器稍微复杂一些，将被装饰函数返回的结果转换成大写字母：

~~~ python
def uppercase(func):
    def wrapper():
    original_result = func()
    modified_result = original_result.upper()
    	return modified_result
	return wrapper
~~~

这个uppercase装饰器不像之前那样直接返回输入函数，而是在其中定 义一个新函数（闭包）。在调用原函数时，新函数会包装原函数来修改 其行为。

装饰器在装饰函数时会返回一个 不同的函数对象，只有这样装饰器才能修改被装饰函数在调用时 的行为。uppercase修饰器本身就是一个函数。对于被装饰的输入函数 来说，修改其“未来行为”的唯一方法是用闭包替换（或包装）这个输入 函数。

**相当于函数在被装饰的那一下装饰器函数已经被执行了，返回的是装饰器内部函数，用于修改被装饰函数在调用时的行为**

装饰器通过包装闭包来修改可调用对象的行为，因此无须永久性地修改 原对象。原可调用对象的行为仅在装饰时才会改变。 利用这种特性可以将可重用的代码块（如日志记录和其他功能）应用于 现有的函数和类。因此装饰器是Python中非常强大的功能，在标准库和 第三方包中经常用到。

### 2.3.3 将多个装饰器应用于一个函数

当然，多个装饰器能应用于一个函数并叠加各自的效果，因此装饰器能 够以组件的形式重复使用。 下面这个例子中有两个装饰器，用于将被装饰函数返回的字符串包装在 HTML标记中。从结果中标签嵌套的方式能看出Python应用多个装饰器 的顺序：

~~~ python
def strong(func):
    def wrapper():
    	return '<strong>' + func() + '</strong>'
    return wrapper
def emphasis(func):
    def wrapper():
    	return '<em>' + func() + '</em>'
    return wrapper

@strong
@emphasis
def greet():
	return 'Hello!'
greet()
'<strong><em>Hello!</em></strong>'
~~~

从结果中能清楚地看出装饰器应用的顺序是从下向上。首先 是@emphasis装饰器包装输入函数，然后@strong装饰器重新包装这个 已经装饰过的函数。 为了帮助自己记忆这个从下到上的顺序，我喜欢称之为装饰器栈 。栈 从底部开始构建，新内容都添加到顶部。

其实称之为“装饰器队列”更准确，因为最先添加的装饰器最先起作用，而不是最后添加的起 作用

如果将上面的例子拆分开来，以传统方式来应用装饰器，那么装饰器函 数调用链如下所示：

~~~ python
decorated_greet = strong(emphasis(greet))
~~~

同样，从中可以看到先应用的是emphasis装饰器，然后由strong装饰 器重新包装前一步生成的包装函数。 这也意味着堆叠过多的装饰器会对性能产生影响，因为这等同于添加许 多嵌套的函数调用。在实践中这一般不是什么问题，但如果在注重性能 的代码中经常使用装饰器，那么要注意这一点。

### 2.3.4 装饰接受参数的函数

~~~ python
"""
@符号:(1)可以自动的把@符下面的函数当成参数进行传递,传递给装饰器
      (2)把旧函数传递给装饰器,返回一个新函数,然后进行赋值替换 func = kuozhan(func) 用返回的新函数替换旧函数：
	 func = newfunc  func() <==> newfunc()
"""
~~~

### 2.3.5 如何编写“可调试”的装饰器

在使用装饰器时，实际上是使用一个函数替换另一个函数。这个过程的 一个缺点是“隐藏”了（未装饰）原函数所附带的一些元数据。 例如，包装闭包隐藏了原函数的名称、文档字符串和参数列表：

这增加了调试程序和使用Python解释器的难度。幸运的是，有一个方法 能避免这个问题：使用Python标准库中的functools.wraps装饰器。在自己的装饰器中使用functools.wraps能够将丢失的元数据从被装 饰的函数复制到装饰器闭包中。来看下面这个例子：

~~~ python
import functools
def uppercase(func):
    @functools.wraps(func)
    def wrapper():
    	return func().upper()
	return wrapper
~~~

将functools.wraps应用到由装饰器返回的封装闭包中，会获得原函 数的文档字符串和其他元数据

## 2.4 * 和 **

*操作符用于将元组、列表和**生成器**等**序列**解包为位置参数。还有用于从字典中解包关键字参数的**操作符。

由于字典是无序的， 因此解包时会匹配字典键和函数参数：x参数接受 字典中与'x'键相关联的值。

> 自Python 3.6开始，字典是有序的，但仅仅是指插入顺序，不是某种“自动排序”。

如果使用单个星号（*）操作符来解包字典，则所有的键将以随机顺序 传递给函数：

~~~ python
dict_vec = {'y': 0, 'z': 1, 'x': 1}
print_vector(*dict_vec)
# <y, x, z>
~~~

## 3.类与面向对象

### 3.1 对象比较：is与==

~~~ python
# a和b指向同一地址
a = [1, 2, 3]
b = a

print(id(a))  # 2245939624832
print(id(b))  # 2245939624832
~~~

## 4.2 字符串转换（每个类都需要`__repr__`）

### 4.2.1 `__str__`与`__repr__`

`__repr__`，其工作方式类似于`__str__`，但用于其他情形。（ 还有一个`__unicode__`方法，后面会介绍。）

~~~ python
class Car:
    def __init__(self, color, mileage):
        self.color = color
        self.mileage = mileage
    def __repr__(self):
    	return '__repr__ for Car'
    def __str__(self):
    	return '__str__ for Car'

>>> my_car = Car('red', 37281)
>>> print(my_car)
__str__ for Car
>>> '{}'.format(my_car)
'__str__ for Car'
>>> my_car
__repr__ for Car
~~~

从实验可以得知，在Python解释器会话中查看对象得到的是对象的 `__repr__`结果。 有趣的是，像列表和字典这样的容器总是使用`__repr__`的结果来表示 所包含的对象，哪怕对容器本身调用str()也是如此：

~~~ python
str([my_car])
'[__repr__ for Car]'
~~~

介绍完`__str__`和`__repr__`之后，你可能想知道它们各自在实际使用 中的差异。这两个函数的目的看上去相同，因此你可能对其各自的使用 场景感到费解。 对于这样的问题，可以看看Python标准库是怎么做的。现在再设计一个 实验，创建一个datetime.date对象，看这个对象如何使用`__repr__`和`__str__`来控制字符串转换：

~~~ python
>>> import datetime
>>> today = datetime.date.today()
>>> str(today)
'2017-02-02'
~~~

在date对象上，`__str__`函数的结果侧重于可读性，旨在为人们返回一 个简洁的文本表示，以便放心地向用户展示。因此在date对象上调 用str()时，得到的是一些看起来像ISO日期格式的东西：

`__repr__`侧重的则是得到无歧义的结果，生成的字符串更多的是帮助 开发人员调试程序。为此需要尽可能明确地说明这个对象是什么，因此 在对象上调用repr()会得到相对更复杂的结果，其中甚至包括完整的 模块和类名称：

~~~ python
repr(today)
'datetime.date(2017, 2, 2)'
~~~

复制并粘贴由这个__repr__返回的字符串，可以作为有效的Python语 句重新创建原date对象。这种方式很不错，在编写自己的repr时值得 借鉴。 然而我发现这个模式实践起来相当困难，通常不值得这么做，因为这只 会带来额外的工作。我的经验法则是只要让__repr__生成的字符串对 开发人员清晰且有帮助就可以了，并不需要能从中恢复对象的完整状 态。

### 4.2.2 为什么每个类都需要`__repr__`

如果不提供__str__方法，Python在查找__str__时会回退到__repr__ 的结果。因此建议总是为自定义类添加__repr__方法，这只需花费很 少的时间，但能保证在几乎所有情况下都能得到可用字符串转换结果。 下面介绍如何快速高效地为自定义类添加基本的字符串转换功能。对于 前面的Car类，首先添加一个__repr__：

~~~ python
def __repr__(self):
	return f'Car({self.color!r}, {self.mileage!r})'
~~~

注意，这里使用!r转换标志来确保输出字符串使用的 是repr(self.color)和repr(self.mileage)，而不 是str(self.color)和str(self.mileage)。 虽然这样能正常工作，但缺点是在格式字符串中硬编码了类名称。有一 种技巧能避免这种硬编码，即使用对象的__class__.__name__属性来 获得以字符串表示的类名称。 这样做的好处是在改变类名称时，不必修改__repr__的实现，因此能 更好地遵循“不要重复自己”（DRY）原则：

~~~ python
def __repr__(self):
    return (f'{self.__class__.__name__}('
    f'{self.color!r}, {self.mileage!r})')
~~~

### 4.2.3 python2.x的差异：`__unicode__`

在Python 3中使用str数据类型表示文本，其中用到了unicode字符，可 以表示世界上大部分书写系统。 使用不同的数据模型来表示字符串。oython2 有两种类型可以表示文 本：str（仅限于ASCII字符集）和unicode（等同于Python 3的str）

由于这种差异，Python 2中还有另一种双下划线方法能够控制字符串转 换：__unicode__。在Python 2中，__str__返回字节， 而__unicode__返回字符。 

大多数情况下应优先使用新的__unicode__方法转换字符串。同时还有 一个内置的unicode()函数，该函数会调用相应的双下划线方法， 与str()和repr()的工作方式相似。 

到目前为止还不错，但Python 2中调用__str__和__unicode__的规则 非常古怪：print语句和str()调用__str__；内置的unicode()先调 用__unicode__，若没有__unicode__则回退到__str__，此时使用系 统文本编码对结果进行解码。 

与Python 3相比，这些特殊情况让文本转换规则变得更加复杂。不过能 针对实际情况进一步简化。unicode是Python程序中处理文本的首选，同 时也是趋势。

所以一般情况下，建议在 python2中将所有字符串格式化代码放 入__unicode__方法中，然后创建一个__str__存根实现，返回以UTF8编码的unicode表示形式：

~~~ python
def __str__(self):
	return unicode(self).encode('utf-8')
~~~

## 4.3 定义自己的异常类

> 定义自己的异常类型能让代码清楚地表达出自己的意图，并易于调 试。

示例：

~~~ python
class MyException(Exception):
    pass
~~~

## 4.6 namedtuple的优点

namedtuple适合在Python中以节省内存的方式快速手动 定义一个不可变的类。

示例：

~~~ python
from collections import namedtuple

Car = namedtuple('Car', 'color mileage')

my_car = Car("red", 123)
my_car[0]  # red
# 解包(还可用于函数参数的解包)
color, mileage = my_car
my_car.color = 'blue'  # 报错，不可变

print(my_car)
~~~

### 4.6.1 子类化namedtuple

可以扩展namedtuple定义的类，往其添加方法：

~~~ python
Car = namedtuple('Car', 'color mileage')
class MyCarWithMethods(Car):
    def hexcolor(self):
        if self.color == 'red':
            return '#ff0000'
        else:
            return '#000000'
~~~

另外，创建namedtuple类层次的最简单方法是使用基类元组的 _fields属性：

~~~ python
from collections import namedtuple

Car = namedtuple('Car', 'color mileage')
ElectricCar = namedtuple('ElectricCar', Car._fields + ('charge',))
e = ElectricCar('red', 1234, 45.0)
print(e)  # ElectricCar(color='red', mileage=1234, charge=45.0)
~~~

### 4.6.3 内置的辅助方法

除了_fields属性，每个namedtuple实例还提供了其他一些有用的辅助 方法。这些方法都以单下划线`_`开头。单下划线通常表示方法或属 性是“私有”的，不是类或模块的稳定公共接口的一部分。

* asdict()

* _replace

  ~~~ python
  # 该方法用于创建一个元组的浅副本，并能够选择替换其中的一些字段
  my_car._replace(color='blue')  # Car(color='blue', mileage=3812.4)
  ~~~

* _make()

  ~~~ python
  # 用来从序列或迭代对象中创建namedtuple的新实例：
  Car._make(['red', 999])
  Car(color='red', mileage=999)
  ~~~



## 5.数据类型

### 5.2 数组数据结构

#### 5.2.3 array.array——基本类型数组

> 数组是可变的，但数据类型是固定的不可变

Python的array模块占用的空间较少，用于存储C语言风格的基本数据 类型（如字节、32位整数，以及浮点数等）。

使用array.array类创建的数组是可变的，行为与列表类似。但有一个 重要的区别：这种数组是单一数据类型的“类型数组”。

由于这个限制，含有多个元素的array.array对象比列表和元组节省空 12 13 13 间。存储在其中的元素紧密排列，因此适合存储许多相同类型的元素。 此外，数组中有许多普通列表中也含有的方法，使用方式也相同，无须 对应用程序代码进行其他更改。

#### 5.2.4 str——含有Unicode字符的不可变数组

> 字符串是递归型数据类型
>
> 最接近“可变字符串”概念的是 14 14 存储单个字符的列表。

~~~ python
type('abc')  # "<class 'str'>"
type('abc'[0])  # "<class 'str'>"
~~~

#### 5.2.5 bytes——含有单字节的不可变数组

> bytes对象是单字节的不可变序列，单字节为0～255（含）范围内的整 数。 从概念上讲，bytes与str对象类似，可认为是不可变的字节数 组。

与字符串一样，也有专门用于创建bytes对象的字面语法，bytes也很 节省空间。bytes对象是不可变的，但与字符串不同，还有一个名 为bytearray的专用“可变字节数组”数据类型，bytes可以解包 到bytearray中。

~~~ python
# bytes 必须位于0～255：
 bytes((0, 300))  # ValueError
    
# bytes 是不可变的：
arr[1] = 23  # TypeError
del arr[1]  # TypeError
~~~

#### 5.2.6 bytearray——含有单字节的可变数组

bytearray类型是可变整数序列 ，包含的整数范围在0～ 255（含）。bytearray与bytes对象关系密切，主要区别在于 bytearray可以自由修改，如覆盖、删除现有元素和添加新元素，此时 bytearray对象将相应地增长和缩小。

bytearray数可以转换回不可变的bytes对象，但是这需要复制所存储 的数据，是耗时为 的慢操作。

~~~ python
# bytearray 可以转换回byte 对象，此过程会复制数据：
arr = bytearray((0, 1, 2, 3))
arr[1] = 23
del arr[1]
arr.append(42)
# bytearray 只能持有byte，即位于0～255 范围内的整数
arr[1] = 'hello'  # TypeError
arr[1] = 300  # ValueError
~~~

### 5.3 记录、结构体和纯数据对象

#### 5.3.5 typing.NamedTuple——改进版namedtuple

> 这个类添加自Python 3.6，是collections模块中namedtuple类的姊妹。 它与namedtuple非常相似，主要区别在于用新语法来定义记录 类型并支持类型注解（type hint）。

示例：

~~~ python
from typing import NamedTuple
class Car(NamedTuple):
    color: str
    mileage: float
    automatic: bool
# 字段是不可变的：
car1.mileage = 12  # AttributionError

# 只有像mypy 这样的类型检查工具才会落实类型注解：
~~~



#### 5.3.6 struct.Struct——序列化C结构体

> struct.Struct类 用于在Python值和C结构体之间转换，并将其序列 化为Python字节对象。例如可以用来处理存储在文件中或来自网络连接 的二进制数据。

结构体使用与格式化字符串类似的语法来定义，能够定义并组织各种C 数据类型（如char、int、long，以及对应的无符号的变体）。

序列化结构体一般不用来表示只在Python代码中处理的数据对象，而主要用作数据交换格式。



#### 5.3.7 types.SimpleNamespace——花哨的属性访问

SimpleNamespace实例将其中的所有键都公开为类属性。 因此访问属性时可以使用obj.key这样的点式语法，不需要用普通字典 的obj['key']方括号索引语法。所有实例默认都包含一个不错的 `__repr__`。 

正如其名，SimpleNamespace很简单，基本上就是扩展版的字典，能 够很好地访问属性并以字符串打印出来，还能自由地添加、修改和删除 属性。

示例：

~~~ python
car1 = SimpleNamespace(color='red', mileage=3812.4, automatic=True)
car1.mileage = 12
car1.windshield = 'broken'
del car1.automatic
~~~

### 5.4 集合和多重集合

#### 5.4.2 frozenset——不可变集合

frozenset类实现了不可变版的集合，即在构造后无法更改。 不可变集合是静态的，只能查询其中的元素（无法插入或删除）。因为不可变集合是静态的且可散列的，所以**可以用作字典的键**，也可以放置在另一 个集合中，普通可变的set对象做不到这一点。

#### 5.4.3 collections.Counter——多重集合

示例：

~~~ python
from collections import Counter

inventory = Counter()
loot = {'sword': 1, 'bread': 3}
inventory.update(loot)
print(inventory)
more_loot = {'sword': 1, 'apple': 1}
inventory.update(more_loot)
print(inventory)
~~~

### 5.5 栈（后进先出）

栈是含有一组对象的容器，支持快速后进先出（LIFO）的插入和删除 操作。与列表或数组不同，栈通常不允许随机访问所包含的对象。插入 和删除操作通常称为入栈（push）和出栈（pop）。

现实世界中与栈数据结构相似的是一叠盘子。

#### 5.5.1 列表——简单的内置栈	

Python的列表在内部以动态数组实现，这意味着在添加或删除时，列表 偶尔需要调整元素的存储空间大小。列表会预先分配一些后备存储空间，因此并非每个入栈或出栈操作都需要调整大小，所以这些操作的为摊时间复杂度为O(1) 。 这么做的缺点是列表的性能不如基于链表的实现（如 collections.deque，下面会介绍），后者能为插入和删除操作提供 稳定的 时间复杂度。另一方面，列表能在 时间快速随机访问堆 栈上的元素，这能带来额外的好处。

#### 5.5.2 collections.deque——快速且稳健的栈

* 基于链表实现

deque类实现了一个双端队列，支持在时间（非均摊）从两端添加和移除元素。因为双端队列支持从两端添加和删除元素，所以既可以作 为队列也可以作为栈。

Python的deque对象以双向链表实现，这为插入和删除元素提供了出色 且一致的性能，但是随机访问位于栈中间元素的性能很差，耗时为O(n)

示例：

~~~ python
from collections import deque

s = deque(maxlen=2)  # 之后保留两位元素，超出的出栈
s.append(1)
s.append(2)
s.append(3)
~~~



#### 5.5.3 queue.LifoQueue——为并行计算提供锁语义

queue.LifoQueue这个位于Python标准库中的栈实现是同步的，提供了 锁语义来支持多个并发的生产者和消费者。

示例：

~~~ python
from queue import LifoQueue

s = LifoQueue()
s.put('eat')
s.put('sleep')
s.put('code')

print(s.get())
print(s.get())
print(s.get())
# print(s.get())  阻塞
print(s.get_nowait())  # 报错
~~~

### 5.6 队列（先进先出）

**先进先出**，与列表或 数组不同，队列通常不允许随机访问所包含的对象。

队列在算法中有广泛的应用，经常用于解决调度和并行编程问题。在树 或图数据结构上进行宽度优先搜索（BFS）是一种简短而美丽的算法， 其中就用到了队列。

调度算法通常在内部使用**优先级队列**。这些是特化的队列，其中元素的 顺序不是基于插入时间，而是基于优先级。

#### 5.6.1 列表——非常慢的队列

由于在起始位 置插入或删除元素需要将所有其他元素都移动一个位置，因此需要的时 间为O(n)

#### 5.6.2 collections.deque——快速和稳健的队列

deque类实现了一个双端队列，支持在O(1) 时间（非均摊）中从任一端 添加和删除元素。由于deque支持从两端添加和移除元素，因此既可用 作队列也可用作栈。

Python的deque对象以双向链表实现。 这为插入和删除元素提供了出 色且一致的性能，但是随机访问位于栈中间元素的性能很差，耗时为O(n)

~~~ python
from collections import deque
q = deque()
q.append("a")
q.appendleft('b')

print(q.pop())
print(q.pop())
~~~

#### 5.6.3 queue.Queue——为并行计算提供的锁语义

queue.Queue在Python标准库中以同步的方式实现，提供了锁语义来支 持多个并发的生产者和消费者。

#### 5.6.4 multiprocessing.Queue——共享作业队列

multiprocessing.Queue作为共享作业队列来实现，允许多个并发 worker并行处理队列中的元素。 由于CPython中存在全局解释器锁 （GIL），因此无法在单个解释器进程上执行某些并行化过程，使得大 家都转向基于进程的并行化。

### 5.7 优先队列

优先队列是一个容器数据结构，使用具有全序关系 的键（例如用数值 表示的权重）来管理元素，以便快速访问容器中键值最小或最大的元 素。

优先级队列通常用于处理调度问题，例如优先考虑更加紧急的任务。

#### 5.7.1 列表——手动维护有序队列

使用有序列表能够快速识别并删除最小或最大的元素，缺点是向列表插 入元素表是很慢的 O(n)操作。 虽然用标准库中的bisect.insort 能在 Olog(n)时间内找到插入位置， 但缓慢的插入操作才是瓶颈。

向列表添加并重新排序来维持顺序也至少需要O(nlogn) 的时间。另一个 缺点是在插入新元素时，必须手动重新排列列表。

#### 5.7.2 heapq——基于列表的二叉堆

heapq是二叉堆，通常用普通列表实现，能在 时间内插入和获取 最小的元素。

heapq模块是在Python中不错的优先级队列实现。由于heapq在技术上只 提供最小堆实现，因此必须添加额外步骤来确保排序稳定性，以此来获 得“实际”的优先级队列中所含有的预期特性。

#### 5.7.3 queue.PriorityQueue——美丽的优先级队列

queue.PriorityQueue这个优先级队列的实现在内部使用了heapq，时 间和空间复杂度与heapq相同。

区别在于PriorityQueue是同步的，提供了锁语义来支持多个并发的生 产者和消费者。

~~~ python
from queue import PriorityQueue
q = PriorityQueue()
q.put((2, 'code'))
q.put((1, 'eat'))
q.put((3, 'sleep'))
while not q.empty():
    next_item = q.get()
    print(next_item)
~~~

如果想避免queue.PriorityQueue的锁开销，那么建议直接使 用heapq模块

## 6.循环和迭代

### 6.1 编写有Python特色的循环

支持迭代，对象需要通过提供`__iter__`和`__next__`双下划线 方法来实现迭代器协议。

range类型表示不可变的数列，内存占用比普通列表少。range对象实 际上并不存储数列的每个值，而是充当迭代器实时计算数列的值。

### 6.2 理解解析式

### 6.3 列表切片技巧与寿司操作员

:操作符清空列表中的所有元素，同 时不会破坏列表对象本身。

~~~ python
lst = [1, 2, 3, 4, 5]
del lst[:]
lst  # []
~~~

### 6.4 美丽的迭代器

在Python中使用迭代器协议，只要对象支持`__iter__`和 `__next__`双下划线方法，那么就能使用for-in循环。

#### 6.4.1 无限迭代

~~~ python
class Repeater:
    def __init__(self, value):
        self.value = value

    def __iter__(self):
        return RepeaterIterator(self)


class RepeaterIterator:
    def __init__(self, source):
        self.source = source

    def __next__(self):
        return self.source.value


repeater = Repeater('Hello')

for item in repeater:
    print(item)
~~~

#### 6.4.3 更简单的迭代器类

~~~ python
class Repeater:
    def __init__(self, value):
        self.value = value

    def __iter__(self):
        return self

    def __next__(self):
        return self.value
~~~

在迭代器协议中，最重要的是__iter__要返回带 有`__next__`方法的**对象**。



#### 6.4.4 不想无限迭代

> 只需在元素迭代完时主动抛出StopIteration错误即可

例1：

~~~ python
class BoundedRepeater:
    def __init__(self, value, max_repeats):
        self.value = value
        self.max_repeats = max_repeats
        self.count = 0

    def __iter__(self):
        return self

    def __next__(self):
        if self.count >= self.max_repeats:
            raise StopIteration
        self.count += 1
        return self.value


repeater = BoundedRepeater('Hello', 3)
for item in repeater:
    print(item)
~~~

例2：

~~~ python
class Repeater:
    def __init__(self, value):
        self.value = value
        self.cursor = 0

    def __iter__(self):
        return self

    def __next__(self):
        if len(self.value) <= self.cursor:
            raise StopIteration
        res = self.value[self.cursor]
        self.cursor += 1
        return res


repeater = Repeater('Hello')

for item in repeater:
    print(item)
~~~

### 6.5 生成器是简化版迭代器

return语句会丢弃函数的局部状态，而yield语句会暂停该函数并保留 其局部状态。实际上，这意味着局部变量和生成器函数的执行状态只是 暂时隐藏起来，不会被完全抛弃。再次调用生成器的next()能够恢复 执行函数

~~~ python
def bounded_repeater1(value, max_repeats):
    count = 0
    while True:
        if count >= max_repeats:
            return
        count += 1
        yield value


for x in bounded_repeater1('Hi', 4):
    print(x)

def bounded_repeater2(value, max_repeats):
    """ 简化版 """
    for i in range(max_repeats):
        yield value


for x in bounded_repeater2('Hi', 4):
    print(x)
~~~



### 6.6 生成器表达式

生成器表达式能够更方便地编写迭代器，看起来像是简化后的列表解析 式语法。生成器表达式用一行代码就能定义迭代器。

~~~ python
iterator = ('Hello' for i in range(3))
~~~

但与列表解析式不同，生成器表达式不会构造列表对象，而是像基于类 的迭代器或生成器函数那样“即时”生成值。

#### 6.63 内联生成器表达式

~~~ python
for x in ('Bom dia' for i in range(3)):
    print(x)
~~~

另外还有一个语法技巧可以美化生成器表达式。如果生成器表达式是作 为函数中的单个参数使用，那么可以删除生成器表达式外层的括号：

~~~ python
sum((x * 2 for x in range(10)))

sum(x * 2 for x in range(10))
~~~

### 6.7 迭代器链

* 生成器可以链接在一起形成高效且可维护的数据处理管道。 
* 互相链接的生成器会**逐个处理**在链中通过的每个元素。 
* 生成器表达式可以用来编写简洁的管道定义，但可能会降低代码的 可读性。

~~~ python
def integers():
    for i in range(1, 9):
        yield i


def squared(seq):
    for i in seq:
        yield i * i


def negated(seq):
    for i in seq:
        yield -i


chain1 = squared(integers())
chain2 = negated(squared(integers()))
~~~



## 7.字典技巧

### 7.3 用字典模拟switch/case语句

Python中头等函数的特性，即函数可以作为参数传递给其他 函数，也可作为其他函数的值返回，还可以分配给变量并存储在数据结 构中。

例子1：

~~~ python
func_dict = {
 'cond_a': func1,
 'cond_b': func1
}
~~~

例子2：

~~~ python
def dispatch_dict(operator, x, y):
    return {
        'add': lambda: x + y,
        'sub': lambda: x - y,
        'mul': lambda: x * y,
        'div': lambda: x / y,
    }.get(operator, lambda: None)()
~~~



### 7.4 “最疯狂”的字典表达式

* Python认为本例中使用的所有字典键都是相等的

~~~ python
a = {True: 'yes', 1: 'no', 1.0: 'maybe'}
print(a)  # {True: 'maybe'}
print(True == 1 == 1.0)  # True
~~~

布尔类型是整数类型的**子类型**，布尔值在几乎所有环境中的行为 都类似于值0和1，但在转换为字符串时，分别得到的是字符 串False或True

这意味着从技术上来说，布尔值可以作为Python中列表或元组的索引：

~~~ python
['no', 'yes'][True]  # yes
~~~

只有键的`__eq__`比较结果和散列值都相同的情况下，字典才会认 为这些是相同的键。

## 8.Python式高效技巧

### 8.2 用virtualenv隔离项目依赖关系

~~~ python
python -m venv 文件夹名
~~~



### 8.3 一窥字节码的究竟

* CPython首先将程序转换为中间字节码，然后在基于栈的虚拟机上 运行字节码来执行程序。 
* 使用内置的dis模块可深入了解并查看字节码。

CPython解释器执行程序时，首先将其翻译成一系列的字节码指令。字 节码是Python虚拟机的中间语言，可以提高程序的执行效率。

在Python 3中，每个函数都有__code__属性，这个属性可以获取greet 函数用到的虚拟机指令、常量和变量：

~~~ python
def greet(name):
    return 'Hello, ' + name + '!'


print(greet.__code__.co_code)  # b'd\x01|\x00\x17\x00d\x02\x17\x00S\x00'
print(greet.__code__.co_consts)  # (None, 'Hello, ', '!')
print(greet.__code__.co_varnames)  # ('name',)
~~~

但看着co_code中复杂的指令 流，似乎有点不现实。这种中间语言显然更适合CPython虚拟机使用， 基于文本的源码才是供人类阅读的。 CPython的开发人员也意识到了这一点，所以提供了另一个称为反汇编 器的工具，以便更容易地查看字节码。

CPython的字节码反汇编程序位于标准库的dis模块中。将其导入并 在greet函数中调用dis.dis()就能以稍微易于阅读的形式显示对应的 字节码：









# 流畅的python(书籍)

## 5.1函数视作对象

> 函数是function类的实例

~~~ python
__doc__属性用于生成对象的帮助文档，help(func)即可查看
函数对象一等性：可以把函数赋值给变量，有了一等函数，就可以使用函数式风格编程。函数式编程的特点之一是使用高阶函数
~~~

## 5.2 高阶函数

定义：能把函数作为参数或返回结果的函数为高阶函数

~~~ python
高阶函数：
map
sorted
filter
reduce  #  Python 3.0 起，reduce 不再是内置函数了。
apply  # 在 Python 2.3 中标记为过时，在 Python 3 中移除
~~~

## 5.3 匿名函数

定义：lambda 句法只是语法糖：与 def 语句一样，lambda 表达式会创建函数对象。这是 Python 中几种可调用对象的一种。

## 5.4可调用对象

如果想判断对象能 否调用，可以使用内置的 callable() 函数。

Python 数据模型文档列出了 7 种可调用对象。

* 用户定义的函数，使用 def 语句或 lambda 表达式创建。
* 内置函数。使用 C 语言（CPython）实现的函数，如 len 或 time.strftime。
* 内置方法。使用 C 语言实现的方法，如 dict.get
* 方法。在类的定义体中定义的函数。
* 类
* 类的实例。如果类定义了 `__call__` 方法，那么它的实例可以作为函数调用。
* 生成器函数。使用 yield 关键字的函数或方法。调用生成器函数返回的是生成器对象。

## 5.5用户定义的可调用类型

不仅 Python 函数是真正的对象，任何 Python 对象都可以表现得像函数。为此，只需实现 实例方法 `__call__` 。

示例：

~~~ python
import random


class BingoCage:
    def __init__(self, items):
        self._items = list(items)
        random.shuffle(self._items)

    def pick(self):
        try:
            return self._items.pop()
        except IndexError:
            raise LookupError('pick from empty BingoCage')

    def __call__(self):
        return self.pick(
~~~

实现 `__call__`方法的类是创建函数类对象的简便方式

## 5.6 函数内省

> dir()函数可以查看对象成员，其中大多数属性是 Python 对象共有的	

下面重点说明函数专有而用户定义的一般对象没有的属性

~~~ python
class C: pass 
obj = C()
def func(): pass
sorted(set(dir(func)) - set(dir(obj)))
'''
['__annotations__', '__call__', '__closure__', '__code__', '__defaults__',
'__get__', '__globals__', '__kwdefaults__', '__name__', '__qualname__']
'''
~~~

| `__annotations__` | `dict`           | 参数和返回值的注解                        |
| ----------------- | ---------------- | ----------------------------------------- |
| `__call__`        | `method-wrapper` | 实现 () 运算符；即可调用对象协议          |
| `__closure__  `   | `tuple`          | 函数闭包，即自由变量的绑定（通常是 None） |
| `__code__`        | `code`           | 编译成字节码的函数元数据和函数定义体      |
| `__defaults__ `   | `tuple`          | 形式参数的默认值                          |
| `__get__`         | `method-wrapper` | 实现只读描述符协议                        |
| `__globals__`     | `dict`           | 函数所在模块中的全局变量                  |
| `__kwdefaults__`  | `dict`           | 仅限关键字形式参数的默认值                |
| `__name__`        | str              | 函数名称                                  |
| `__qualname__`    | `str`            | 函 数 的 限 定 名 称， 如 `Random.choice` |



## 5.7从定位参数到仅限关键字参数

~~~ python
def tag(name, *content, cls=None, **attrs):
    """生成一个或多个HTML标签"""
    if cls is not None:
        attrs['class'] = cls
    if attrs:
        attr_str = ''.join(' %s="%s"' % (attr, value)
                           for attr, value
                           in sorted(attrs.items()))
    else:
        attr_str = ''
    if content:
        return '\n'.join('<%s%s>%s</%s>' %
                         (name, attr_str, c, name) for c in content)
    else:
        return '<%s%s />' % (name, attr_str)
~~~

定义函数时若想指定仅限关键字参数，要把它们 放到前面有 * 的参数后面。

~~~ python
def f(a, *, b):
	return a, b 
~~~

## 5.8　获取关于参数的信息





# 16 协程

字典为动词“to yield”给出了两个释义：产出和让步。对于 Python 生成器中的 yield 来 说，这两个含义都成立。yield item 这行代码会产出一个值，提供给 next(...) 的调用方； 此外，还会作出让步，暂停执行生成器，让调用方继续工作，直到需要使用另一个值时再 调用 next()。调用方会从生成器中**拉取值**。 

从句法上看，协程与生成器类似，都是定义体中包含 yield 关键字的函数。可是，在协程 中，yield 通常出现在表达式的右边（例如，datum = yield），可以产出值，也可以不产 出——如果 yield 关键字后面没有表达式，那么生成器产出 None。协程可能会从调用方接 收数据，不过调用方把数据提供给协程使用的是 .send(datum) 方法，而不是 next(...) 函 数。通常，调用方会把值推送给协程。

 yield 关键字甚至还可以不接收或传出数据。不管数据如何流动，yield 都是一种流程控制 工具，使用它可以实现协作式多任务：**协程可以把控制器让步给中心调度程序，从而激活 其他的协程。**

从根本上把 yield 视作控制流程的方式，这样就好理解协程了。

## 16.1　生成器如何进化成协程

协程的底层架构在`PEP 342`中定义，并在Python2.5(2006年)实现了。自此之后，yield 关 键字可以在表达式中使用，而且生成器 API 中增加了 .send(value) 方法。生成器的调用方 可以使用 .send(...) 方法发送数据，发送的数据会成为生成器函数中 **yield 表达式的值**。 因此，生成器可以作为协程使用。**协程是指一个过程，这个过程与调用方协作，产出由调 用方提供的值。**

除了 .send(...) 方法，PEP 342 还添加了 .throw(...) 和 .close() 方法：前者的作用是让 调用方抛出异常，在生成器中处理；后者的作用是终止生成器。

协程最近的演进来自 Python 3.3（2012 年）实现的“PEP 380—Syntax for Delegating to a Subgenerator”（https://www.python.org/dev/peps/pep-0380/）。PEP 380 对生成器函数的句法 做了两处改动，以便更好地作为协程使用。

* 现在，生成器可以返回一个值；以前，如果在生成器中给 return 语句提供值，会抛出 SyntaxError 异常。 
* 新引入了 yield from 句法，使用它可以把复杂的生成器重构成小型的**嵌套生成器**，省 去了之前把生成器的工作委托给子生成器所需的大量样板代码。

协程可以身处四个状态中的一个。当前状态可以使用 inspect.getgeneratorstate(...) 函 数确定，该函数会返回下述字符串中的一个。

'GEN_CREATED' 等待开始执行。 'GEN_RUNNING' 解释器正在执行。1 'GEN_SUSPENDED' 在 yield 表达式处暂停。 'GEN_CLOSED' 执行结束。

示例：

~~~ python
import inspect


def simple_coroutine():
    print('-> coroutine started')
    x = yield
    print('-> coroutine received:', x)


my_coro = simple_coroutine()

status1 = inspect.getgeneratorstate(my_coro)
print(1, status1)  # GEN_CREATED
# 首先要调用 next(...) 函数或send一个None，因为生成器还没启动，没在 yield 语句处暂停，所以一开始无法发送数据。
print(2, my_coro.send(None))
status2 = inspect.getgeneratorstate(my_coro)
print(3, status2)  # GEN_SUSPENDED
my_coro.send(111)
~~~

因为 send 方法的参数会成为暂停的 yield 表达式的值，所以，仅当协程处于暂停状态时才 能调用 send 方法，例如 my_coro.send(42)。不过，如果协程还没激活（即，状态是 'GEN_ CREATED'），情况就不同了。因此，始终要调用 next(my_coro) 激活协程——也可以调用 my_coro.send(None)，效果一样。

如果创建协程对象后立即把 None 之外的值发给它，会出现下述错误：

~~~ python
my_coro = simple_coroutine()
my_coro.send(1729)
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
TypeError: can't send non-None value to a just-started generator
~~~

最先调用 next(my_coro) 函数这一步通常称为“预激”（prime）协程（即，让协程向前执 行到第一个 yield 表达式，准备好作为活跃的协程使用）。

~~~ python
def simple_coro2(a):
	print('-> Started: a =', a)
	b = yield a
	print('-> Received: b =', b)
	c = yield a + b
	print('-> Received: c =', c) 
~~~



## 16.3 使用协程计算移动平均值

示例：

~~~ python
def averager():
    total = 0
    count = 0
    average = None
    while True:
        term = yield average
        total += term
        count += 1
        average = total / count
aver = averager()
print(next(aver))
print(aver.send(10))
print(aver.send(30))
print(aver.send(5))
~~~

这个无限循环表明，只要调用方不断把值发给这个协程，它就会一直接收值，然后生成 结果。仅当调用方在协程上调用 .close() 方法，或者没有对协程的引用而被垃圾回收 程序回收时，这个协程才会终止。

这里的 yield 表达式用于暂停执行协程，把结果发给调用方；还用于接收调用方后面发 给协程的值，恢复无限循环。

调用 next(coro_avg) 函数后，协程会向前执行到 yield 表达式，产出 average 变量的初始值——None，因此不会出现在控制台中。此时，协程在 yield 表达式处暂停，等到调用方发送值。coro_avg.send(10) 那一行发送一个值，激活 协程，把发送的值赋给 term，并更新 total、count 和 average 三个变量的值，然后开始 while 循环的下一次迭代，产出 average 变量的值，等待下一次为 term 变量赋值。

使用协程之前必须预激，可是这一 步容易忘记。为了避免忘记，可以在协程上使用一个特殊的装饰器。接下来介绍这样一个 装饰器。

## 16.4 预激协程的装饰器

如果不预激，那么协程没什么用。

示例：预激协程的装饰器

~~~ python
from functools import wraps
def coroutine(func): 
    """装饰器：向前执行到第一个`yield`表达式，预激`func`"""
     @wraps(func)
     def primer(*args,**kwargs):
         gen = func(*args,**kwargs)
         next(gen)
         return gen
     return primer
~~~

很多框架都提供了处理协程的特殊装饰器，不过不是所有装饰器都用于预激协程，有些会 提供其他服务，例如勾入事件循环。比如说，异步网络库 Tornado 提供了 tornado.gen 装 饰器（http://tornado.readthedocs.org/en/latest/gen.html）。

 使用 yield from 句法（参见 16.7 节）调用协程时，会**自动预激**，因此与示例中的 @coroutine 等装饰器不兼容。Python 3.4 标准库里的 asyncio.coroutine 装饰器（第 18 章 介绍）不会预激协程，因此能兼容 yield from 句法。

## 16.5 终止协程和异常处理

协程中未处理的异常会向上冒泡，传给 next 函数或 send 方法的调用方（即触发协程的对 象）。示例 16-7 举例说明如何使用示例 16-6 中由装饰器定义的 averager 协程。

~~~ python
>>> from coroaverager1 import averager
>>> coro_avg = averager()
>>> coro_avg.send(40) # 
40.0
>>> coro_avg.send(50)
45.0
>>> coro_avg.send('spam') # ➋
Traceback (most recent call last):
 ...
TypeError: unsupported operand type(s) for +=: 'float' and 'str'
# 由于在协程内没有处理异常，协程会终止。 如果试图重新激活协程， 会抛出StopIteration 异常。
>>> coro_avg.send(60)
Traceback (most recent call last):
 File "<stdin>", line 1, in <module>
StopIteration
~~~

示例中暗示了终止协程的一种方式：发送某个哨符值，让协程退出。内置的 None 和 Ellipsis 等常量经常用作哨符值。Ellipsis 的优点是，数据流中不太常有这个值。我还见 过有人把 StopIteration 类（类本身，而不是实例，也不抛出）作为哨符值；也就是说， 是像这样使用的：my_coro.send(StopIteration)。

从 Python 2.5 开始，客户代码可以在生成器对象上调用两个方法，显式地把异常发给协程。这两个方法是 throw 和 close。

generator.throw(exc_type[, exc_value[, traceback]])   致使生成器在暂停的 yield 表达式处抛出指定的异常。如果生成器处理了抛出的异常， 代码会向前执行到下一个 yield 表达式，而产出的值会成为调用 generator.throw 方法 得到的返回值。如果生成器没有处理抛出的异常，异常会向上冒泡，传到调用方的上下 文中。 

generator.close()  致使生成器在暂停的 yield 表达式处抛出 GeneratorExit 异常。如果生成器没有处 理这个异常，或者抛出了 StopIteration 异常（通常是指运行到结尾），调用方不会 报错。如果收到 GeneratorExit 异常，生成器一定不能产出值，否则解释器会抛出 RuntimeError 异常。生成器抛出的其他异常会**向上冒泡**，传给调用方。

下面举例说明如何使用 close 和 throw 方法控制协程。

~~~ python
class DemoException(Exception):
    """为这次演示定义的异常类型。"""


def demo_exc_handling():
    print('-> coroutine started')
    while True:
        try:
            x = yield
        except DemoException:
            print('*** DemoException handled. Continuing...')
        else:
            print('-> coroutine received: {!r}'.format(x))
    raise RuntimeError('This line should never run.')


exc_coro = demo_exc_handling()
next(exc_coro)
exc_coro.send(11)
# exc_coro.send(22)
exc_coro.throw(ZeroDivisionError) 
from inspect import getgeneratorstate
print(getgeneratorstate(exc_coro))  # CLOSED
~~~

如果不管协程如何结束都想做些清理工作，要把协程定义体中相关的代码放入 try/ finally 块中，如示例 16-12。

~~~ python
class DemoException(Exception):
    """为这次演示定义的异常类型。"""

def demo_finally():
    print('-> coroutine started')
    try:
        while True:
            try:
                x = yield
            except DemoException:
                print('*** DemoException handled. Continuing...')
            else:
                print('-> coroutine received: {!r}'.format(x))
    finally:
        print('-> coroutine ending')
~~~

Python 3.3 引入 yield from 结构的主要原因之一与把异常传入嵌套的协程有关。另一个原 因是让协程更方便地返回值。请继续往下读，了解详情。

## 16.6让协程返回值

定义一个求平均值的协程，让它返回一个结果

~~~ python
from collections import namedtuple

Result = namedtuple('Result', 'count average')


def averager():
    total = 0.0
    count = 0
    average = None
    while True:
        term = yield  # 不产出值。
        if term is None:
            break
        total += term
        count += 1
        average = total / count
    return Result(count, average)
~~~

返回一个 namedtuple，包含 count 和 average 两个字段。在 Python 3.3 之前，如果生成 器返回值，解释器会报句法错误。

注意，return 表达式的值会偷偷传给调用方，赋值给 StopIteration 异常的一个属性。这样 做有点不合常理，但是能保留生成器对象的常规行为——耗尽时抛出 StopIteration 异常。



# 协程 & 异步编程(asyncio)

协程（Coroutine），也可以被称为微线程，是一种用户态内的上下文切换技术。简而言之，其实就是通过一个线程实现代码块相互切换执行。例如：

```python
def func1():
	print(1)
    ...
	print(2)
	
def func2():
	print(3)
    ...
	print(4)

func1()
func2()
```

上述代码是普通的函数定义和执行，按流程分别执行两个函数中的代码，并先后会输出：`1、2、3、4`。但如果介入协程技术那么就可以实现函数见代码切换执行，最终输入：`1、3、2、4` 。



## 1. 协程的实现

在Python中有多种方式可以实现协程，例如：

- greenlet，是一个第三方模块，用于实现协程代码（Gevent协程就是基于greenlet实现）
- yield，生成器，借助生成器的特点也可以实现协程代码。
- asyncio，在Python3.4中引入的模块用于编写协程代码。
- async & awiat，在Python3.5中引入的两个关键字，结合asyncio模块可以更方便的编写协程代码。



### 1.1 greenlet

greentlet是一个第三方模块，需要提前安装 `pip3 install greenlet`才能使用。

```python
from greenlet import greenlet


def func1():
    print(1)        # 第1步：输出 1
    gr2.switch()    # 第3步：切换到 func2 函数
    print(2)        # 第6步：输出 2
    gr2.switch()    # 第7步：切换到 func2 函数，从上一次执行的位置继续向后执行


def func2():
    print(3)        # 第4步：输出 3
    gr1.switch()    # 第5步：切换到 func1 函数，从上一次执行的位置继续向后执行
    print(4)        # 第8步：输出 4


gr1 = greenlet(func1)
gr2 = greenlet(func2)
gr1.switch() # 第1步：去执行 func1 函数
```

注意：switch中也可以传递参数用于在切换执行时相互传递值。



### 1.2 yield

基于Python的生成器的yield和yield form关键字实现协程代码。

```python
def func1():
    yield 1
    yield from func2()
    yield 2


def func2():
    yield 3
    yield 4


f1 = func1()
for item in f1:
    print(item)
```

注意：yield form关键字是在Python3.3中引入的。



### 1.3 asyncio

在Python3.4之前官方未提供协程的类库，一般大家都是使用greenlet等其他来实现。在Python3.4发布后官方正式支持协程，即：asyncio模块。

```python
import asyncio

@asyncio.coroutine
def func1():
    print(1)
    yield from asyncio.sleep(2)  # 遇到IO耗时操作，自动化切换到tasks中的其他任务
    print(2)


@asyncio.coroutine
def func2():
    print(3)
    yield from asyncio.sleep(2) # 遇到IO耗时操作，自动化切换到tasks中的其他任务
    print(4)


tasks = [
    asyncio.ensure_future(func1()),
    asyncio.ensure_future(func2())
]

loop = asyncio.get_event_loop()
loop.run_until_complete(asyncio.wait(tasks))
```

注意：基于asyncio模块实现的协程比之前的要更厉害，因为他的内部还集成了遇到IO耗时操作自动切换的功能。



### 1.4 async & awit

async & awit 关键字在Python3.5版本中正式引入，基于他编写的协程代码其实就是 上一示例 的加强版，让代码可以更加简便。

Python3.8之后 `@asyncio.coroutine` 装饰器就会被移除，推荐使用async & awit 关键字实现协程代码。

```python
import asyncio


async def func1():
    print(1)
    await asyncio.sleep(2)
    print(2)


async def func2():
    print(3)
    await asyncio.sleep(2)
    print(4)


tasks = [
    asyncio.ensure_future(func1()),
    asyncio.ensure_future(func2())
]

loop = asyncio.get_event_loop()
loop.run_until_complete(asyncio.wait(tasks))
```

### 1.5 小结

关于协程有多种实现方式，目前主流使用是Python官方推荐的asyncio模块和async&await关键字的方式，例如：在tonado、sanic、fastapi、django3 中均已支持。

接下来，我们也会针对 `asyncio模块` + `async & await` 关键字进行更加详细的讲解。



## 2.协程的意义

通过学习，我们已经了解到协程可以通过一个线程在多个上下文中进行来回切换执行。

<span>**但是**</span>，协程来回切换执行的意义何在呢？（网上看到很多文章舔协程，协程牛逼之处是哪里呢？）

```
计算型的操作，利用协程来回切换执行，没有任何意义，来回切换并保存状态 反倒会降低性能。
IO型的操作，利用协程在IO等待时间就去切换执行其他任务，当IO操作结束后再自动回调，那么就会大大节省资源并提供性能，从而实现异步编程（不等待任务结束就可以去执行其他代码）。
```

### 2.1 爬虫案例

例如：用代码实现下载 `url_list` 中的图片。

- 方式一：同步编程实现

  ```python
  """
  下载图片使用第三方模块requests，请提前安装：pip3 install requests
  """
  import requests
  
  
  def download_image(url):
  	print("开始下载:",url)
      # 发送网络请求，下载图片
      response = requests.get(url)
  	print("下载完成")
      # 图片保存到本地文件
      file_name = url.rsplit('_')[-1]
      with open(file_name, mode='wb') as file_object:
          file_object.write(response.content)
  
  
  if __name__ == '__main__':
      url_list = [
          'https://www3.autoimg.cn/newsdfs/g26/M02/35/A9/120x90_0_autohomecar__ChsEe12AXQ6AOOH_AAFocMs8nzU621.jpg',
          'https://www2.autoimg.cn/newsdfs/g30/M01/3C/E2/120x90_0_autohomecar__ChcCSV2BBICAUntfAADjJFd6800429.jpg',
          'https://www3.autoimg.cn/newsdfs/g26/M0B/3C/65/120x90_0_autohomecar__ChcCP12BFCmAIO83AAGq7vK0sGY193.jpg'
      ]
      for item in url_list:
          download_image(item)
  ```

- 方式二：基于协程的异步编程实现

  ```python
  """
  下载图片使用第三方模块aiohttp，请提前安装：pip3 install aiohttp
  """
  #!/usr/bin/env python
  # -*- coding:utf-8 -*-
  import aiohttp
  import asyncio
  
  
  async def fetch(session, url):
      print("发送请求：", url)
      async with session.get(url, verify_ssl=False) as response:
          content = await response.content.read()
          file_name = url.rsplit('_')[-1]
          with open(file_name, mode='wb') as file_object:
              file_object.write(content)
  
  
  async def main():
      async with aiohttp.ClientSession() as session:
          url_list = [
              'https://www3.autoimg.cn/newsdfs/g26/M02/35/A9/120x90_0_autohomecar__ChsEe12AXQ6AOOH_AAFocMs8nzU621.jpg',
              'https://www2.autoimg.cn/newsdfs/g30/M01/3C/E2/120x90_0_autohomecar__ChcCSV2BBICAUntfAADjJFd6800429.jpg',
              'https://www3.autoimg.cn/newsdfs/g26/M0B/3C/65/120x90_0_autohomecar__ChcCP12BFCmAIO83AAGq7vK0sGY193.jpg'
          ]
          tasks = [asyncio.create_task(fetch(session, url)) for url in url_list]
  
          await asyncio.wait(tasks)
  
  
  if __name__ == '__main__':
      asyncio.run(main())  # run方法内部调用了loop.run_until_complete方法
  
  ```

上述两种的执行对比之后会发现，`基于协程的异步编程` 要比 `同步编程`的效率高了很多。因为：

- 同步编程，按照顺序逐一排队执行，如果图片下载时间为2分钟，那么全部执行完则需要6分钟。
- 异步编程，几乎同时发出了3个下载任务的请求（遇到IO请求自动切换去发送其他任务请求），如果图片下载时间为2分钟，那么全部执行完毕也大概需要2分钟左右就可以了。



### 2.2 小结

协程一般应用在有IO操作的程序中，因为协程可以利用IO等待的时间去执行一些其他的代码，从而提升代码执行效率。

生活中不也是这样的么，假设 你是一家制造汽车的老板，员工点击设备的【开始】按钮之后，在设备前需等待30分钟，然后点击【结束】按钮，此时作为老板的你一定希望这个员工在等待的那30分钟的时间去做点其他的工作。



## 3.异步编程

基于`async` & `await`关键字的协程可以实现异步编程，这也是目前python异步相关的主流技术。

想要真正的了解Python中内置的异步编程，根据下文的顺序一点点来看。

### 3.1 事件循环

事件循环，可以把他当做是一个while循环，这个while循环在周期性的运行并执行一些`任务`，在特定条件下终止循环。

```python
# 伪代码

任务列表 = [ 任务1, 任务2, 任务3,... ]

while True:
    可执行的任务列表，已完成的任务列表 = 去任务列表中检查所有的任务，将'可执行'和'已完成'的任务返回
    
    for 就绪任务 in 已准备就绪的任务列表:
        执行已就绪的任务
        
    for 已完成的任务 in 已完成的任务列表:
        在任务列表中移除 已完成的任务

	如果 任务列表 中的任务都已完成，则终止循环
```

在编写程序时候可以通过如下代码来获取和创建事件循环。

```python
import asyncio

loop = asyncio.get_event_loop()
```



### 3.2 协程和异步编程

协程函数，定义形式为 [`async def`](https://docs.python.org/zh-cn/3.8/reference/compound_stmts.html#async-def) 的函数。

协程对象，调用 *协程函数* 所返回的对象。

```python
# 定义一个协程函数
async def func():
    pass

# 调用协程函数，返回一个协程对象
result = func()
```

**注意**：调用协程函数时，函数内部代码不会执行，只是会返回一个协程对象。

#### 3.2.1 基本应用

程序中，如果想要执行协程函数的内部代码，需要 `事件循环` 和 `协程对象` 配合才能实现，如：

```python
import asyncio


async def func():
    print("协程内部代码")

# 调用协程函数，返回一个协程对象。
result = func()

# 方式一
loop = asyncio.get_event_loop() # 创建一个事件循环
loop.run_until_complete(result) # 将协程当做任务提交到事件循环的任务列表中，协程执行完成之后终止。

# 方式二
# 本质上方式一是一样的，内部先 创建事件循环(一个新的) 然后执行 run_until_complete，一个简便的写法。
# asyncio.run 函数在 Python 3.7 中加入 asyncio 模块，
asyncio.run(result)  # 接收一个协程对象
```

这个过程可以简单理解为：将`协程`当做任务添加到 `事件循环` 的任务列表，然后事件循环检测列表中的`协程`是否 已准备就绪（默认可理解为就绪状态），如果准备就绪则执行其内部代码。

#### 3.2.2 await

await是一个只能在协程函数中使用的关键字，用于遇到IO操作时挂起 当前协程（任务），当前协程（任务）挂起过程中 事件循环可以去执行其他的协程（任务），当前协程IO处理完成时，可以再次切换回来执行await之后的代码。代码如下：

**示例1：**

```python
import asyncio


async def func():
    print("执行协程函数内部代码")

    # 遇到IO操作挂起当前协程（任务），等IO操作完成之后再继续往下执行。
    # 当前协程挂起时，事件循环可以去执行其他协程（任务）。
    response = await asyncio.sleep(2)

    print("IO请求结束，结果为：", response)

result = func()

asyncio.run(result)
```



**示例2：**

```python
import asyncio


async def others():
    print("start")
    await asyncio.sleep(2)
    print('end')
    return '返回值'


async def func():
    print("执行协程函数内部代码")

    # 遇到IO操作挂起当前协程（任务），等IO操作完成之后再继续往下执行。当前协程挂起时，事件循环可以去执行其他协程（任务）。
    response = await others()

    print("IO请求结束，结果为：", response)
    
asyncio.run( func() )
```

**示例3：**

```python
import asyncio


async def others():
    print("start")
    await asyncio.sleep(2)
    print('end')
    return '返回值'


async def func():
    print("执行协程函数内部代码")

    # 遇到IO操作挂起当前协程（任务），等IO操作完成之后再继续往下执行。当前协程挂起时，事件循环可以去执行其他协程（任务）。
    response1 = await others()
    print("IO请求结束，结果为：", response1)
    
    response2 = await others()
    print("IO请求结束，结果为：", response2)
    
asyncio.run( func() )
```

上述的所有示例都只是创建了一个任务，即：事件循环的任务列表中只有一个任务，所以在IO等待时无法演示切换到其他任务效果。

在程序想要创建多个任务对象，需要使用Task对象来实现。



#### 3.2.3 Task对象

> *Tasks* are used to schedule coroutines *concurrently*.
>
> When a coroutine is wrapped into a *Task* with functions like [`asyncio.create_task()`](https://docs.python.org/3.8/library/asyncio-task.html#asyncio.create_task) the coroutine is automatically scheduled to run soon。

Tasks用于并发调度协程，通过`asyncio.create_task(协程对象)`的方式创建Task对象，这样可以让协程加入事件循环中等待被调度执行。除了使用 `asyncio.create_task()` 函数以外，还可以用低层级的 `loop.create_task()` 或 `ensure_future()` 函数。不建议手动实例化 Task 对象。

`Task`继承了`Future`类, `ensure_future`内部实际上调用了`loop.create_task`创建`task`, `asyncio.create_task()`内部同样是调用了`loop.create_task`



本质上是将协程对象封装成task对象，并将协程立即加入事件循环，同时追踪协程的状态。

注意：`asyncio.create_task()` 函数在 Python 3.7 中被加入。在 Python 3.7 之前，可以改用低层级的 `asyncio.ensure_future()` 函数。

**示例1：**

```python
import asyncio


async def func():
    print(1)
    await asyncio.sleep(2)
    print(2)
    return "返回值"


async def main():
    print("main开始")

    # 创建协程，将协程封装到一个Task对象中并立即添加到事件循环的任务列表中，等待事件循环去执行（默认是就绪状态）。
    task1 = asyncio.create_task(func())

    # 创建协程，将协程封装到一个Task对象中并立即添加到事件循环的任务列表中，等待事件循环去执行（默认是就绪状态）。
    task2 = asyncio.create_task(func())

    print("main结束")

    # 当执行某协程遇到IO操作时，会自动化切换执行其他任务。
    # 此处的await是等待相对应的协程全都执行完毕并获取结果
    ret1 = await task1
    ret2 = await task2
    print(ret1, ret2)


asyncio.run(main())
```



**示例2：**

```python
import asyncio


async def func():
    print(1)
    await asyncio.sleep(2)
    print(2)
    return "返回值"


async def main():
    print("main开始")

    # 创建协程，将协程封装到Task对象中并添加到事件循环的任务列表中，等待事件循环去执行（默认是就绪状态）。
    # 在调用
    task_list = [
        asyncio.create_task(func(), name="n1"),
        asyncio.create_task(func(), name="n2")
    ]

    print("main结束")

    # 当执行某协程遇到IO操作时，会自动化切换执行其他任务。
    # 此处的await是等待所有协程执行完毕，并将所有协程的返回值保存到done
    # 如果设置了timeout值，则意味着此处最多等待的秒，完成的协程返回值写入到done中，未完成则写到pending中。
    done, pending = await asyncio.wait(task_list, timeout=None)  # wait接收一个task(future)序列
    print(done, pending)


asyncio.run(main())
```

注意：`asyncio.wait` 源码内部会对列表中的每个协程执行ensure_future从而封装为Task对象，所以在和wait配合使用时task_list的值为`[func(),func()]` 也是可以的。`ensure_future`源码内部会判断如果是协程就将其封装为Task对象，如果已经是Task对象，则判断是否为当前loop，并将其Task对象返回

**示例3：**

```python
import asyncio


async def func():
    print("执行协程函数内部代码")

    # 遇到IO操作挂起当前协程（任务），等IO操作完成之后再继续往下执行。当前协程挂起时，事件循环可以去执行其他协程（任务）。
    response = await asyncio.sleep(2)

    print("IO请求结束，结果为：", response)


coroutine_list = [func(), func()]

# 错误：coroutine_list = [ asyncio.create_task(func()), asyncio.create_task(func()) ]
# 此处不能直接 asyncio.create_task，因为将Task立即加入到"正在运行的"事件循环的任务列表，
# 但此时事件循环还未创建，所以会报错。

# 错误：coroutine_list = [asyncio.ensure_future(func()), asyncio.ensure_future(func())]
# 此处不能直接ensure_future,因为ensure_future会创建一个loop,而run会新建一个loop,两者会冲突
# run_until_complete  --> run_forever中设置了running_loop

# 使用asyncio.wait将列表封装为一个协程，并调用asyncio.run实现执行两个协程
# asyncio.wait内部会对列表中的每个协程执行ensure_future，封装为Task对象。
done,pending = asyncio.run( asyncio.wait(coroutine_list) )  # 会先执行run方法，run会新创建一个loop
```



#### 3.2.4 asyncio.Future对象

> A `Future`is a special **low-level** awaitable object that represents an **eventual result** of an asynchronous operation.

asyncio中的Future对象是一个相对更偏向底层的可对象，通常我们不会直接用到这个对象，而是直接使用Task对象来完成任务的并和状态的追踪。（ Task 是 Futrue的子类 ）

Future为我们提供了异步编程中的 最终结果 的处理（Task类也具备状态处理的功能）。

示例1：

```python
async def main():
    # 获取当前事件循环
    loop = asyncio.get_running_loop()

    # # 创建一个任务（Future对象），这个任务什么都不干。
    fut = loop.create_future()

    # 等待任务最终结果（Future对象），没有结果则会一直等下去。
    await fut

asyncio.run(main())
```

示例2：

```python
import asyncio


async def set_after(fut):
    await asyncio.sleep(2)
    fut.set_result("666")


async def main():
    # 获取当前事件循环
    loop = asyncio.get_running_loop()

    # 创建一个任务（Future对象），没绑定任何行为，则这个任务永远不知道什么时候结束。
    fut = loop.create_future()

    # 创建一个任务（Task对象），绑定了set_after函数，函数内部在2s之后，会给fut赋值。
    # 即手动设置future任务的最终结果，那么fut就可以结束了。
    await loop.create_task(set_after(fut))

    # 等待 Future对象获取 最终结果，否则一直等下去
    data = await fut
    print(data)

asyncio.run(main())
```

Future对象本身函数进行绑定，所以想要让事件循环获取Future的结果，则需要手动设置。而Task对象继承了Future对象，其实就对Future进行扩展，他可以实现在对应绑定的函数执行完成之后，自动执行`set_result`，从而实现自动结束。

虽然，平时使用的是Task对象，但对于结果的处理本质是基于`Future`对象来实现的。



扩展：支持 `await 对象`语法的对象课成为可等待对象，所以 `协程对象`、`Task对象`、`Future对象` 都可以被成为可等待对象。

#### 3.2.5 futures.Future对象

在Python的`concurrent.futures`模块中也有一个Future对象，这个对象是基于线程池或进程池实现异步操作时使用的对象。

```python
import time
from concurrent.futures import Future
from concurrent.futures.thread import ThreadPoolExecutor
from concurrent.futures.process import ProcessPoolExecutor


def func(value):
    time.sleep(1)
    print(value)


pool = ThreadPoolExecutor(max_workers=5)
# 或 pool = ProcessPoolExecutor(max_workers=5)


for i in range(10):
    fut = pool.submit(func, i)
    print(fut)
```

两个Future对象是不同的，他们是为不同的应用场景而设计，例如：`concurrent.futures.Future`不支持await语法 等。

官方提示两对象之间不同：

- unlike asyncio Futures, [`concurrent.futures.Future`](https://docs.python.org/3.8/library/concurrent.futures.html#concurrent.futures.Future) instances cannot be awaited.

- [`asyncio.Future.result()`](https://docs.python.org/3.8/library/asyncio-future.html#asyncio.Future.result) and [`asyncio.Future.exception()`](https://docs.python.org/3.8/library/asyncio-future.html#asyncio.Future.exception) do not accept the *timeout* argument.
- [`asyncio.Future.result()`](https://docs.python.org/3.8/library/asyncio-future.html#asyncio.Future.result) and [`asyncio.Future.exception()`](https://docs.python.org/3.8/library/asyncio-future.html#asyncio.Future.exception) raise an [`InvalidStateError`](https://docs.python.org/3.8/library/asyncio-exceptions.html#asyncio.InvalidStateError) exception when the Future is not *done*.
- Callbacks registered with [`asyncio.Future.add_done_callback()`](https://docs.python.org/3.8/library/asyncio-future.html#asyncio.Future.add_done_callback) are not called immediately. They are scheduled with [`loop.call_soon()`](https://docs.python.org/3.8/library/asyncio-eventloop.html#asyncio.loop.call_soon) instead.
- asyncio Future is not compatible with the [`concurrent.futures.wait()`](https://docs.python.org/3.8/library/concurrent.futures.html#concurrent.futures.wait) and [`concurrent.futures.as_completed()`](https://docs.python.org/3.8/library/concurrent.futures.html#concurrent.futures.as_completed) functions.



在Python提供了一个将`futures.Future` 对象包装成`asyncio.Future`对象的函数 `asynic.wrap_future`。

接下里你肯定问：为什么python会提供这种功能？

其实，一般在程序开发中我们要么统一使用 asycio 的协程实现异步操作、要么都使用进程池和线程池实现异步操作。但如果 `协程的异步`和 `进程池/线程池的异步` 混搭时，那么就会用到此功能了。场景：比如在使用异步编程时，某些第三方模块不支持异步，在这时需要用线程池或进程池实现协程，返回一个Future对象，然后再使用asyncio.wrap_future将concurrent.futures.Future对象包装为asycio.Future对象，这样在某种意义上也实现了协程

```python
import time
import asyncio
import concurrent.futures

def func1():
    # 某个耗时操作
    time.sleep(2)
    return "SB"

async def main():
    loop = asyncio.get_running_loop()

    # 1. Run in the default loop's executor ( 默认ThreadPoolExecutor )
    # 第一步：内部会先调用 ThreadPoolExecutor 的 submit 方法去线程池中申请一个线程去执行func1函数，并返回一个concurrent.futures.Future对象
    # 第二步：调用asyncio.wrap_future将concurrent.futures.Future对象包装为asycio.Future对象。
    # 因为concurrent.futures.Future对象不支持await语法，所以需要包装为 asycio.Future对象 才能使用。
    fut = loop.run_in_executor(None, func1)  # 查看源码即可
    result = await fut
    print('default thread pool', result)

    # 2. Run in a custom thread pool:
    # with concurrent.futures.ThreadPoolExecutor() as pool:
    #     result = await loop.run_in_executor(
    #         pool, func1)
    #     print('custom thread pool', result)

    # 3. Run in a custom process pool:
    # with concurrent.futures.ProcessPoolExecutor() as pool:
    #     result = await loop.run_in_executor(
    #         pool, func1)
    #     print('custom process pool', result)

asyncio.run(main())
```



应用场景：当项目以协程式的异步编程开发时，如果要使用一个第三方模块，而第三方模块不支持协程方式异步编程时，就需要用到这个功能，例如：

```python
import asyncio
import requests


async def download_image(url):
    # 发送网络请求，下载图片（遇到网络下载图片的IO请求，自动化切换到其他任务）
    print("开始下载:", url)

    loop = asyncio.get_event_loop()
    # requests模块默认不支持异步操作，所以就使用线程池来配合实现了。
    future = loop.run_in_executor(None, requests.get, url)

    response = await future
    print('下载完成')
    # 图片保存到本地文件
    file_name = url.rsplit('_')[-1]
    with open(file_name, mode='wb') as file_object:
        file_object.write(response.content)


if __name__ == '__main__':
    url_list = [
        'https://www3.autoimg.cn/newsdfs/g26/M02/35/A9/120x90_0_autohomecar__ChsEe12AXQ6AOOH_AAFocMs8nzU621.jpg',
        'https://www2.autoimg.cn/newsdfs/g30/M01/3C/E2/120x90_0_autohomecar__ChcCSV2BBICAUntfAADjJFd6800429.jpg',
        'https://www3.autoimg.cn/newsdfs/g26/M0B/3C/65/120x90_0_autohomecar__ChcCP12BFCmAIO83AAGq7vK0sGY193.jpg'
    ]

    tasks = [download_image(url) for url in url_list]

    loop = asyncio.get_event_loop()
    loop.run_until_complete( asyncio.wait(tasks) )
```



#### 3.2.6 异步迭代器

**什么是异步迭代器**

实现了 [`__aiter__()`](https://docs.python.org/zh-cn/3.8/reference/datamodel.html#object.__aiter__) 和 [`__anext__()`](https://docs.python.org/zh-cn/3.8/reference/datamodel.html#object.__anext__) 方法的对象。`__anext__` 必须返回一个 [awaitable](https://docs.python.org/zh-cn/3.8/glossary.html#term-awaitable) 对象。[`async for`](https://docs.python.org/zh-cn/3.8/reference/compound_stmts.html#async-for) 会处理异步迭代器的 [`__anext__()`](https://docs.python.org/zh-cn/3.8/reference/datamodel.html#object.__anext__) 方法所返回的可等待对象，直到其引发一个 [`StopAsyncIteration`](https://docs.python.org/zh-cn/3.8/library/exceptions.html#StopAsyncIteration) 异常。由 [**PEP 492**](https://www.python.org/dev/peps/pep-0492) 引入。

**什么是异步可迭代对象？**

可在 [`async for`](https://docs.python.org/zh-cn/3.8/reference/compound_stmts.html#async-for) 语句中被使用的对象。必须通过它的 [`__aiter__()`](https://docs.python.org/zh-cn/3.8/reference/datamodel.html#object.__aiter__) 方法返回一个 [asynchronous iterator](https://docs.python.org/zh-cn/3.8/glossary.html#term-asynchronous-iterator)。由 [**PEP 492**](https://www.python.org/dev/peps/pep-0492) 引入。

```python
import asyncio


class Reader(object):
    """ 自定义异步迭代器（同时也是异步可迭代对象） """

    def __init__(self):
        self.count = 0

    async def readline(self):
        # await asyncio.sleep(1)
        self.count += 1
        if self.count == 100:
            return None
        return self.count

    def __aiter__(self):
        return self

    async def __anext__(self):
        val = await self.readline()
        if val == None:
            raise StopAsyncIteration
        return val


async def func():
    # 创建异步可迭代对象
    async_iter = Reader()
    # async for 必须要放在async def函数内，否则语法错误。
    async for item in async_iter:
        print(item)

asyncio.run(func())
```

异步迭代器其实没什么太大的作用，只是支持了async for语法而已。

#### 3.2.6 异步上下文管理器

此种对象通过定义 [`__aenter__()`](https://docs.python.org/zh-cn/3.8/reference/datamodel.html#object.__aenter__) 和 [`__aexit__()`](https://docs.python.org/zh-cn/3.8/reference/datamodel.html#object.__aexit__) 方法来对 [`async with`](https://docs.python.org/zh-cn/3.8/reference/compound_stmts.html#async-with) 语句中的环境进行控制。由 [**PEP 492**](https://www.python.org/dev/peps/pep-0492) 引入。

```python
import asyncio


class AsyncContextManager:
	def __init__(self):
        self.conn = conn
        
    async def do_something(self):
        # 异步操作数据库
        return 666

    async def __aenter__(self):
        # 异步链接数据库
        self.conn = await asyncio.sleep(1)
        return self

    async def __aexit__(self, exc_type, exc, tb):
        # 异步关闭数据库链接
		await asyncio.sleep(1)


async def func():
    async with AsyncContextManager() as f:
        result = await f.do_something()
        print(result)


asyncio.run(func())
```

这个异步的上下文管理器还是比较有用的，平时在开发过程中 打开、处理、关闭 操作时，就可以用这种方式来处理。



### 3.3 小结

在程序中只要看到`async`和`await`关键字，其内部就是基于协程实现的异步编程，这种异步编程是通过一个线程在IO等待时间去执行其他任务，从而实现并发。

以上就是异步编程的常见操作，内容参考官方文档。

- 中文版：https://docs.python.org/zh-cn/3.8/library/asyncio.html
- 英文本：https://docs.python.org/3.8/library/asyncio.html



## 4. uvloop

Python标准库中提供了`asyncio`模块，用于支持基于协程的异步编程。

uvloop是 asyncio 中的事件循环的替代方案，替换后可以使得asyncio性能提高。事实上，uvloop要比nodejs、gevent等其他python异步框架至少要快2倍，性能可以比肩Go语言。

安装uvloop

```
pip3 install uvloop
```

在项目中想要使用uvloop替换asyncio的事件循环也非常简单，只要在代码中这么做就行。

```python
import asyncio
import uvloop
asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())

# 编写asyncio的代码，与之前写的代码一致。

# 内部的事件循环自动化会变为uvloop
asyncio.run(...)
```

注意：知名的asgi uvicorn内部就是使用的uvloop的事件循环。



## 5.实战案例

为了更好理解，上述所有示例的IO情况都是以 `asyncio.sleep` 为例，而真实的项目开发中会用到很多IO的情况。

### 5.1 异步Redis

当通过python去操作redis时，链接、设置值、获取值 这些都涉及网络IO请求，使用asycio异步的方式可以在IO等待时去做一些其他任务，从而提升性能。

安装Python异步操作redis模块

```
pip3 install aioredis
```

示例1：异步操作redis。

```python
#!/usr/bin/env python
# -*- coding:utf-8 -*-
import asyncio
import aioredis


async def execute(address, password):
    print("开始执行", address)
    # 网络IO操作：创建redis连接
    redis = await aioredis.create_redis(address, password=password)

    # 网络IO操作：在redis中设置哈希值car，内部在设三个键值对，即： redis = { car:{key1:1,key2:2,key3:3}}
    await redis.hmset_dict('car', key1=1, key2=2, key3=3)

    # 网络IO操作：去redis中获取值
    result = await redis.hgetall('car', encoding='utf-8')
    print(result)

    redis.close()
    # 网络IO操作：关闭redis连接
    await redis.wait_closed()

    print("结束", address)


asyncio.run(execute('redis://47.93.4.198:6379', "root!2345"))
```



示例2：连接多个redis做操作（遇到IO会切换其他任务，提供了性能）。

```python
import asyncio
import aioredis


async def execute(address, password):
    print("开始执行", address)

    # 网络IO操作：先去连接 47.93.4.197:6379，遇到IO则自动切换任务，去连接47.93.4.198:6379
    redis = await aioredis.create_redis_pool(address, password=password)

    # 网络IO操作：遇到IO会自动切换任务
    await redis.hmset_dict('car', key1=1, key2=2, key3=3)

    # 网络IO操作：遇到IO会自动切换任务
    result = await redis.hgetall('car', encoding='utf-8')
    print(result)

    redis.close()
    # 网络IO操作：遇到IO会自动切换任务
    await redis.wait_closed()

    print("结束", address)


task_list = [
    execute('redis://47.93.4.197:6379', "root!2345"),
    execute('redis://47.93.4.198:6379', "root!2345")
]

asyncio.run(asyncio.wait(task_list))
```

更多redis操作参考aioredis官网：https://aioredis.readthedocs.io/en/v1.3.0/start.html



### 5.2 异步MySQL

当通过python去操作MySQL时，连接、执行SQL、关闭都涉及网络IO请求，使用asycio异步的方式可以在IO等待时去做一些其他任务，从而提升性能。

安装Python异步操作redis模块

```
pip3 install aiomysql
```

示例1：

```python
import asyncio
import aiomysql


async def execute():
    # 网络IO操作：连接MySQL
    conn = await aiomysql.connect(host='127.0.0.1', port=3306, user='root', password='123', db='mysql', )

    # 网络IO操作：创建CURSOR
    cur = await conn.cursor()

    # 网络IO操作：执行SQL
    await cur.execute("SELECT Host,User FROM user")

    # 网络IO操作：获取SQL结果
    result = await cur.fetchall()
    print(result)

    # 网络IO操作：关闭链接
    await cur.close()
    conn.close()


asyncio.run(execute())
```

示例2：

```python
#!/usr/bin/env python
# -*- coding:utf-8 -*-
import asyncio
import aiomysql


async def execute(host, password):
    print("开始", host)
    # 网络IO操作：先去连接 47.93.40.197，遇到IO则自动切换任务，去连接47.93.40.198:6379
    conn = await aiomysql.connect(host=host, port=3306, user='root', password=password, db='mysql')

    # 网络IO操作：遇到IO会自动切换任务
    cur = await conn.cursor()

    # 网络IO操作：遇到IO会自动切换任务
    await cur.execute("SELECT Host,User FROM user")

    # 网络IO操作：遇到IO会自动切换任务
    result = await cur.fetchall()
    print(result)

    # 网络IO操作：遇到IO会自动切换任务
    await cur.close()
    conn.close()
    print("结束", host)


task_list = [
    execute('47.93.40.197', "root!2345"),
    execute('47.93.40.197', "root!2345")
]

asyncio.run(asyncio.wait(task_list))
```



### 5.3 FastAPI框架

FastAPI是一款用于构建API的高性能web框架，框架基于Python3.6+的 `type hints`搭建。

接下里的异步示例以`FastAPI`和`uvicorn`来讲解（uvicorn是一个支持异步的asgi）。

安装FastAPI web 框架，

```
pip3 install fastapi
```

安装uvicorn，本质上为web提供socket server的支持的asgi（一般支持异步称asgi、不支持异步称wsgi）

```
pip3 install uvicorn
```

示例：

```python
#!/usr/bin/env python
# -*- coding:utf-8 -*-
import asyncio

import uvicorn
import aioredis
from aioredis import Redis
from fastapi import FastAPI

app = FastAPI()

REDIS_POOL = aioredis.ConnectionsPool('redis://47.193.14.198:6379', password="root123", minsize=1, maxsize=10)


@app.get("/")
def index():
    """ 普通操作接口 """
    return {"message": "Hello World"}


@app.get("/red")
async def red():
    """ 异步操作接口 """
    
    print("请求来了")

    await asyncio.sleep(3)
    # 连接池获取一个连接
    conn = await REDIS_POOL.acquire()
    redis = Redis(conn)

    # 设置值
    await redis.hmset_dict('car', key1=1, key2=2, key3=3)

    # 读取值
    result = await redis.hgetall('car', encoding='utf-8')
    print(result)

    # 连接归还连接池
    REDIS_POOL.release(conn)

    return result


if __name__ == '__main__':
    uvicorn.run("luffy:app", host="127.0.0.1", port=5000, log_level="info")
```

在有多个用户并发请求的情况下，异步方式来编写的接口可以在IO等待过程中去处理其他的请求，提供性能。

例如：同时有两个用户并发来向接口 `http://127.0.0.1:5000/red` 发送请求，服务端只有一个线程，同一时刻只有一个请求被处理。  异步处理可以提供并发是因为：当视图函数在处理第一个请求时，第二个请求此时是等待被处理的状态，当第一个请求遇到IO等待时，会自动切换去接收并处理第二个请求，当遇到IO时自动化切换至其他请求，一旦有请求IO执行完毕，则会再次回到指定请求向下继续执行其功能代码。

### 5.4 爬虫

在编写爬虫应用时，需要通过网络IO去请求目标数据，这种情况适合使用异步编程来提升性能，接下来我们使用支持异步编程的aiohttp模块来实现。

安装aiohttp模块

```
pip3 install aiohttp
```

示例：

```python
import aiohttp
import asyncio


async def fetch(session, url):
    print("发送请求：", url)
    async with session.get(url, verify_ssl=False) as response:
        text = await response.text()
        print("得到结果：", url, len(text))


async def main():
    async with aiohttp.ClientSession() as session:
        url_list = [
            'https://python.org',
            'https://www.baidu.com',
            'https://www.pythonav.com'
        ]
        tasks = [asyncio.create_task(fetch(session, url)) for url in url_list]

        await asyncio.wait(tasks)


if __name__ == '__main__':
    asyncio.run(main())
```



## 总结

为了提升性能越来越多的框架都在向异步编程靠拢，例如：sanic、tornado、django3.0、django channels组件 等，用更少资源可以做处理更多的事，何乐而不为呢。

# websockets

~~~python
"""
handler是管理连接的协程。当客户端连接时，websockets调用带有连接参数的handler。当处理程序终止时，websockets关闭连接。
每当客户端连接时，服务器就创建一个WebSocketServerProtocol，执行开始握手，并委托给连接处理程序ws_handler。
处理程序接收 WebSocketServerProtocol 并使用它来发送和接收消息。
一旦处理程序(handler)正常或异常地完成，服务器将执行结束握手并关闭连接。
"""

import asyncio
import websockets


async def handler(websocket):
    while True:
        message = await websocket.recv()
        print(message)
        # 它支持异步迭代来接收消息
        # async for message in websocket:
        #	print(message)

async def handler(websocket):
    """
    当客户端断开连接时，服务器正在使用recv()等待下一条消息。当这种情况发生时，
    websockets抛出一个ConnectionClosedOK异常，让你知道你不会在这个连接上接收到其他消息。
    """
    while True:
        try:
            message = await websocket.recv()
        except websockets.ConnectionClosedOK:  # 连接正确时
            break
        except websockets.ConnectionClosedError:  # 连接错误时
            break
        print(message)


# #########启动服务的三种方式
async def main1():
    # 作为异步上下文管理器调用serve()，可以确保服务器在终止程序时正确关闭。
    async with websockets.serve(handler, "localhost", 8001): 
        # 创建一个任务（Future对象），没绑定任何行为，则这个任务永远不知道什么时候结束。
        await asyncio.Future()  # run forever

async def main2():
    # Set the stop condition when receiving SIGTERM.
    loop = asyncio.get_running_loop()
    stop = loop.create_future()
    loop.add_signal_handler(signal.SIGTERM, stop.set_result, None)  # 终止信号，软件终止信号

    async with websockets.serve(
        echo,
        host="",
        port=8080,
        reuse_port=True,
    ):
        await stop  # 一直等待，直到set_result

async def main3():
    loop = asyncio.get_event_loop()
    loop.run_until_complete(websockets.serve(ws_child_line_protocol, 'localhost', 8765, reuse_port=True,))
    loop.run_forever()


if __name__ == "__main__":
    asyncio.run(main1())
~~~

## broadcast

~~~ python
for connection in connected:
        await connection.send(json.dumps(event))

# connected(ws连接)
websockets.broadcast(connected, json.dumps(data))

# 一次调用broadcast()比在循环中调用send()更有效。
~~~

## 加密连接

> 安全的WebSocket连接提高了机密性和可靠性，因为它们减少了被坏代理干扰的风险。
>
> wss协议之于ws就像https之于http。该连接使用TLS(传输层安全)加密。WSS需要像https这样的证书。
>
> TLS有时也称为SSL(安全套接字层)。SSL是早期的加密协议;the name stuck.

下面介绍如何调整服务器以加密连接。您必须下载localhost。并将其保存在与server_secure.py相同的目录中。

有关安全配置TLS上下文的详细信息，请参见ssl模块的文档。

~~~ python
import asyncio
import pathlib
import ssl
import websockets

async def hello(websocket):
    name = await websocket.recv()
    print(f"<<< {name}")

    greeting = f"Hello {name}!"

    await websocket.send(greeting)
    print(f">>> {greeting}")

ssl_context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)
localhost_pem = pathlib.Path(__file__).with_name("localhost.pem")
ssl_context.load_cert_chain(localhost_pem)

async def main():
    async with websockets.serve(hello, "localhost", 8765, ssl=ssl_context):
        await asyncio.Future()  # run forever

if __name__ == "__main__":
    asyncio.run(main())
~~~

客户端

~~~ python
import asyncio
import pathlib
import ssl
import websockets

ssl_context = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)
localhost_pem = pathlib.Path(__file__).with_name("localhost.pem")
ssl_context.load_verify_locations(localhost_pem)

async def hello():
    uri = "wss://localhost:8765"
    async with websockets.connect(uri, ssl=ssl_context) as websocket:
        name = input("What's your name? ")

        await websocket.send(name)
        print(f">>> {name}")

        greeting = await websocket.recv()
        print(f"<<< {greeting}")

if __name__ == "__main__":
    asyncio.run(hello())
~~~
